{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyPZUddXzIFfTu5knR+m6+ao"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["step 0"],"metadata":{"id":"JbuvNzxfFDyg"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OsXu56QXEK69","executionInfo":{"status":"ok","timestamp":1762163516179,"user_tz":0,"elapsed":3473,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"abfabf78-727e-48c8-9021-3ef0f6cb1207"},"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","ENVIRONMENT FINGERPRINT\n","======================================================================\n","\n","Timestamp: 2025-11-03T09:51:56.031617+00:00\n","\n","Python:    3.12.12\n","Platform:  Linux-6.6.105+-x86_64-with-glibc2.35\n","\n","GPU Configuration-----------------------------------------------------\n","  Name:          NVIDIA L4\n","  Driver:        550.54.15\n","  CUDA:          12.6\n","  CUDA Avail:    True\n","  Device Count:  1\n","  Memory:        341/23034 MB\n","  Power Limit:   72.0 W\n","  P-State:       8\n","\n","Energy Counter--------------------------------------------------------\n","  Supported:     True\n","  Units:         mJ\n","  Note:          TotalEnergyConsumption supported\n","\n","Library Versions------------------------------------------------------\n","  PyTorch:       2.8.0+cu126\n","  NumPy:         2.0.2\n","\n","Reproducibility-------------------------------------------------------\n","  Seeds:         42 (Python/NumPy/Torch)\n","  Deterministic: Enabled\n","\n","======================================================================\n","✓ Environment fingerprint saved to logs/env.json\n","✓ NVIDIA-SMI output saved to logs/nvidia_smi.txt\n","✓ Dependencies saved to logs/pip_freeze.txt\n","======================================================================\n"]}],"source":["import os\n","import json\n","import subprocess\n","import sys\n","import platform\n","import random\n","from datetime import datetime, timezone\n","import numpy as np\n","import torch\n","\n","os.makedirs('logs', exist_ok=True)\n","\n","nvidia_smi_output = subprocess.run(['nvidia-smi', '-q'], capture_output=True, text=True)\n","with open('logs/nvidia_smi.txt', 'w') as f:\n","    f.write(nvidia_smi_output.stdout)\n","\n","subprocess.run(['pip', 'freeze'], stdout=open('logs/pip_freeze.txt', 'w'))\n","\n","import pynvml\n","pynvml.nvmlInit()\n","\n","try:\n","    device_count = pynvml.nvmlDeviceGetCount()\n","    handle = pynvml.nvmlDeviceGetHandleByIndex(0) if device_count > 0 else None\n","\n","    _to_str = lambda x: x.decode(\"utf-8\") if isinstance(x, (bytes, bytearray)) else str(x)\n","\n","    if handle:\n","        gpu_name = _to_str(pynvml.nvmlDeviceGetName(handle))\n","        driver_version = _to_str(pynvml.nvmlSystemGetDriverVersion())\n","\n","        memory_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n","        power_limit = pynvml.nvmlDeviceGetPowerManagementLimit(handle) / 1000.0\n","\n","        try:\n","            pstate = pynvml.nvmlDeviceGetPerformanceState(handle)\n","        except:\n","            pstate = \"N/A\"\n","\n","        try:\n","            _ = pynvml.nvmlDeviceGetTotalEnergyConsumption(handle)\n","            energy_support = True\n","            energy_note = \"TotalEnergyConsumption supported\"\n","        except pynvml.NVMLError:\n","            energy_support = False\n","            energy_note = \"TotalEnergyConsumption NOT supported, will use power sampling integration\"\n","\n","        gpu_info = {\n","            \"name\": gpu_name,\n","            \"driver_version\": driver_version,\n","            \"device_count\": device_count,\n","            \"memory_total_mb\": memory_info.total // (1024**2),\n","            \"memory_used_mb\": memory_info.used // (1024**2),\n","            \"power_limit_w\": power_limit,\n","            \"performance_state\": str(pstate)\n","        }\n","    else:\n","        gpu_info = {\n","            \"name\": \"N/A\",\n","            \"driver_version\": \"N/A\",\n","            \"device_count\": 0\n","        }\n","        energy_support = False\n","        energy_note = \"No NVIDIA GPU detected\"\n","\n","finally:\n","    pynvml.nvmlShutdown()\n","\n","cuda_available = torch.cuda.is_available()\n","cuda_version = torch.version.cuda if cuda_available else None\n","gpu_info[\"cuda_version\"] = cuda_version\n","gpu_info[\"cuda_available\"] = cuda_available\n","\n","random.seed(42)\n","np.random.seed(42)\n","torch.manual_seed(42)\n","if cuda_available:\n","    torch.cuda.manual_seed_all(42)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    torch.use_deterministic_algorithms(True)\n","    os.environ.setdefault(\"CUBLAS_WORKSPACE_CONFIG\", \":4096:8\")\n","\n","env_info = {\n","    \"timestamp\": datetime.now(timezone.utc).isoformat(),\n","    \"python_version\": sys.version,\n","    \"platform\": platform.platform(),\n","    \"gpu\": gpu_info,\n","    \"energy_counter\": {\n","        \"supported\": energy_support,\n","        \"units\": \"mJ\",\n","        \"note\": energy_note\n","    },\n","    \"library_versions\": {\n","        \"torch\": torch.__version__,\n","        \"numpy\": np.__version__\n","    },\n","    \"random_seeds\": {\n","        \"python\": 42,\n","        \"numpy\": 42,\n","        \"torch\": 42\n","    },\n","    \"reproducibility\": {\n","        \"cudnn_deterministic\": cuda_available,\n","        \"cudnn_benchmark\": False,\n","        \"deterministic_algorithms\": cuda_available\n","    }\n","}\n","\n","with open('logs/env.json', 'w') as f:\n","    json.dump(env_info, f, indent=2)\n","\n","print(\"=\" * 70)\n","print(\"ENVIRONMENT FINGERPRINT\")\n","print(\"=\" * 70)\n","print(f\"\\nTimestamp: {env_info['timestamp']}\")\n","print(f\"\\nPython:    {sys.version.split()[0]}\")\n","print(f\"Platform:  {env_info['platform']}\")\n","print(f\"\\n{'GPU Configuration':-<70}\")\n","print(f\"  Name:          {gpu_info['name']}\")\n","print(f\"  Driver:        {gpu_info['driver_version']}\")\n","print(f\"  CUDA:          {cuda_version}\")\n","print(f\"  CUDA Avail:    {cuda_available}\")\n","print(f\"  Device Count:  {gpu_info['device_count']}\")\n","if handle:\n","    print(f\"  Memory:        {gpu_info['memory_used_mb']}/{gpu_info['memory_total_mb']} MB\")\n","    print(f\"  Power Limit:   {gpu_info['power_limit_w']:.1f} W\")\n","    print(f\"  P-State:       {gpu_info['performance_state']}\")\n","print(f\"\\n{'Energy Counter':-<70}\")\n","print(f\"  Supported:     {energy_support}\")\n","print(f\"  Units:         mJ\")\n","print(f\"  Note:          {energy_note}\")\n","print(f\"\\n{'Library Versions':-<70}\")\n","print(f\"  PyTorch:       {torch.__version__}\")\n","print(f\"  NumPy:         {np.__version__}\")\n","print(f\"\\n{'Reproducibility':-<70}\")\n","print(f\"  Seeds:         42 (Python/NumPy/Torch)\")\n","print(f\"  Deterministic: {'Enabled' if cuda_available else 'N/A (no CUDA)'}\")\n","print(\"\\n\" + \"=\" * 70)\n","print(\"✓ Environment fingerprint saved to logs/env.json\")\n","print(\"✓ NVIDIA-SMI output saved to logs/nvidia_smi.txt\")\n","print(\"✓ Dependencies saved to logs/pip_freeze.txt\")\n","print(\"=\" * 70)"]},{"cell_type":"markdown","source":["step 1"],"metadata":{"id":"BtgKGOhRFHGR"}},{"cell_type":"code","source":["import os\n","import json\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler\n","import urllib.request\n","import zipfile\n","\n","os.makedirs('configs', exist_ok=True)\n","os.makedirs('data', exist_ok=True)\n","\n","print(\"Downloading UCI HAR Dataset...\")\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\"\n","zip_path = \"data/uci_har.zip\"\n","urllib.request.urlretrieve(url, zip_path)\n","\n","print(\"Extracting dataset...\")\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(\"data/\")\n","\n","data_root = \"data/UCI HAR Dataset\"\n","\n","def load_inertial_signals(root_path, split='train'):\n","    signals = ['body_acc_x', 'body_acc_y', 'body_acc_z',\n","               'body_gyro_x', 'body_gyro_y', 'body_gyro_z',\n","               'total_acc_x', 'total_acc_y', 'total_acc_z']\n","\n","    data_list = []\n","    for signal in signals:\n","        filepath = f\"{root_path}/{split}/Inertial Signals/{signal}_{split}.txt\"\n","        data = np.loadtxt(filepath)\n","        data_list.append(data)\n","\n","    X = np.stack(data_list, axis=2)\n","\n","    y = np.loadtxt(f\"{root_path}/{split}/y_{split}.txt\").astype(int) - 1\n","    subject = np.loadtxt(f\"{root_path}/{split}/subject_{split}.txt\").astype(int)\n","\n","    return X, y, subject\n","\n","print(\"Loading raw inertial signals...\")\n","train_x, train_y, train_subjects = load_inertial_signals(data_root, 'train')\n","test_x, test_y, test_subjects = load_inertial_signals(data_root, 'test')\n","\n","activity_labels = {}\n","with open(f\"{data_root}/activity_labels.txt\", 'r') as f:\n","    for line in f:\n","        idx, label = line.strip().split()\n","        activity_labels[int(idx) - 1] = label\n","\n","print(f\"Train shape: {train_x.shape}, Test shape: {test_x.shape}\")\n","\n","gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n","train_idx, val_idx = next(gss.split(train_x, train_y, groups=train_subjects))\n","\n","val_x = train_x[val_idx]\n","val_y = train_y[val_idx]\n","val_subjects = train_subjects[val_idx]\n","\n","train_x = train_x[train_idx]\n","train_y = train_y[train_idx]\n","train_subjects = train_subjects[train_idx]\n","\n","n_samples_train, window_samples, n_channels = train_x.shape\n","\n","scaler = StandardScaler()\n","train_x_reshaped = train_x.reshape(-1, n_channels)\n","scaler.fit(train_x_reshaped)\n","\n","train_x = scaler.transform(train_x.reshape(-1, n_channels)).reshape(train_x.shape)\n","val_x = scaler.transform(val_x.reshape(-1, n_channels)).reshape(val_x.shape)\n","test_x = scaler.transform(test_x.reshape(-1, n_channels)).reshape(test_x.shape)\n","\n","n_features = n_channels\n","n_classes = len(activity_labels)\n","sampling_rate_hz = 50\n","window_ms = 2560\n","overlap = 0.5\n","\n","refresh_rates_hz = [0.1, 0.5, 1.0, 2.0]\n","\n","total_samples = len(train_x) + len(val_x) + len(test_x)\n","actual_train_ratio = len(train_x) / total_samples\n","actual_val_ratio = len(val_x) / total_samples\n","actual_test_ratio = len(test_x) / total_samples\n","\n","config = {\n","    \"dataset\": \"UCI_HAR\",\n","    \"data_format\": \"raw_inertial_signals\",\n","    \"n_samples\": {\n","        \"train\": len(train_x),\n","        \"val\": len(val_x),\n","        \"test\": len(test_x)\n","    },\n","    \"n_features\": n_features,\n","    \"n_classes\": n_classes,\n","    \"class_labels\": activity_labels,\n","    \"window\": {\n","        \"window_ms\": window_ms,\n","        \"window_samples\": window_samples,\n","        \"sampling_rate_hz\": sampling_rate_hz,\n","        \"overlap\": overlap,\n","        \"note\": \"Fixed window from dataset, cannot be modified\"\n","    },\n","    \"window_grid_applicable\": False,\n","    \"refresh_rates_hz\": refresh_rates_hz,\n","    \"data_split\": {\n","        \"method\": \"group_shuffle_split_by_subject\",\n","        \"train_ratio\": round(actual_train_ratio, 3),\n","        \"val_ratio\": round(actual_val_ratio, 3),\n","        \"test_ratio\": round(actual_test_ratio, 3),\n","        \"random_seed\": 42,\n","        \"n_train_subjects\": len(np.unique(train_subjects)),\n","        \"n_val_subjects\": len(np.unique(val_subjects)),\n","        \"n_test_subjects\": len(np.unique(test_subjects))\n","    },\n","    \"preprocessing\": {\n","        \"standardization\": \"StandardScaler (fit on train, per-channel)\",\n","        \"per_inference_mode\": True\n","    },\n","    \"shape\": {\n","        \"train\": list(train_x.shape),\n","        \"format\": \"(n_samples, window_samples, n_channels)\"\n","    }\n","}\n","\n","with open('configs/windows.json', 'w') as f:\n","    json.dump(config, f, indent=2)\n","\n","np.save('data/train_x.npy', train_x)\n","np.save('data/train_y.npy', train_y)\n","np.save('data/val_x.npy', val_x)\n","np.save('data/val_y.npy', val_y)\n","np.save('data/test_x.npy', test_x)\n","np.save('data/test_y.npy', test_y)\n","\n","split_info = pd.DataFrame({\n","    'split': ['train', 'val', 'test'],\n","    'n_samples': [len(train_x), len(val_x), len(test_x)],\n","    'n_subjects': [len(np.unique(train_subjects)),\n","                   len(np.unique(val_subjects)),\n","                   len(np.unique(test_subjects))],\n","    'window_samples': [window_samples, window_samples, window_samples],\n","    'n_channels': [n_channels, n_channels, n_channels]\n","})\n","split_info.to_csv('data/split_info.csv', index=False)\n","\n","print(\"=\" * 70)\n","print(\"DATA & WINDOW CONFIGURATION\")\n","print(\"=\" * 70)\n","print(f\"\\nDataset: {config['dataset']} (Raw Inertial Signals)\")\n","print(f\"\\n{'Data Splits (Subject-Grouped)':-<70}\")\n","print(f\"  Train:     {len(train_x):>6} samples ({len(np.unique(train_subjects)):>2} subjects)\")\n","print(f\"  Val:       {len(val_x):>6} samples ({len(np.unique(val_subjects)):>2} subjects)\")\n","print(f\"  Test:      {len(test_x):>6} samples ({len(np.unique(test_subjects)):>2} subjects)\")\n","print(f\"\\n{'Actual Ratios':-<70}\")\n","print(f\"  Train/Val/Test: {actual_train_ratio:.3f} / {actual_val_ratio:.3f} / {actual_test_ratio:.3f}\")\n","print(f\"\\n{'Data Properties':-<70}\")\n","print(f\"  Shape:     (N, {window_samples}, {n_channels})\")\n","print(f\"  Channels:  {n_channels} (body_acc xyz, body_gyro xyz, total_acc xyz)\")\n","print(f\"  Classes:   {n_classes}\")\n","print(f\"  Sampling:  {sampling_rate_hz} Hz\")\n","print(f\"\\n{'Fixed Window (Dataset Native)':-<70}\")\n","print(f\"  Duration:  {window_ms} ms ({window_ms/1000:.2f} s)\")\n","print(f\"  Samples:   {window_samples}\")\n","print(f\"  Overlap:   {overlap*100:.0f}%\")\n","print(f\"  Note:      Window cannot be modified (pre-segmented dataset)\")\n","print(f\"\\n{'Refresh Rate Grid (for mJ/s calculation)':-<70}\")\n","print(f\"  {refresh_rates_hz} Hz\")\n","print(f\"\\n{'Class Labels (0-indexed)':-<70}\")\n","for idx, label in activity_labels.items():\n","    print(f\"  {idx}: {label}\")\n","print(\"\\n\" + \"=\" * 70)\n","print(\"✓ Configuration saved to configs/windows.json\")\n","print(\"✓ Preprocessed data saved to data/*.npy\")\n","print(\"✓ Split info saved to data/split_info.csv\")\n","print(\"=\" * 70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sftUAswtENOx","executionInfo":{"status":"ok","timestamp":1762163526579,"user_tz":0,"elapsed":10393,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"bce3f554-4afb-44e8-f6b6-378316edca01"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading UCI HAR Dataset...\n","Extracting dataset...\n","Loading raw inertial signals...\n","Train shape: (7352, 128, 9), Test shape: (2947, 128, 9)\n","======================================================================\n","DATA & WINDOW CONFIGURATION\n","======================================================================\n","\n","Dataset: UCI_HAR (Raw Inertial Signals)\n","\n","Data Splits (Subject-Grouped)-----------------------------------------\n","  Train:       5551 samples (16 subjects)\n","  Val:         1801 samples ( 5 subjects)\n","  Test:        2947 samples ( 9 subjects)\n","\n","Actual Ratios---------------------------------------------------------\n","  Train/Val/Test: 0.539 / 0.175 / 0.286\n","\n","Data Properties-------------------------------------------------------\n","  Shape:     (N, 128, 9)\n","  Channels:  9 (body_acc xyz, body_gyro xyz, total_acc xyz)\n","  Classes:   6\n","  Sampling:  50 Hz\n","\n","Fixed Window (Dataset Native)-----------------------------------------\n","  Duration:  2560 ms (2.56 s)\n","  Samples:   128\n","  Overlap:   50%\n","  Note:      Window cannot be modified (pre-segmented dataset)\n","\n","Refresh Rate Grid (for mJ/s calculation)------------------------------\n","  [0.1, 0.5, 1.0, 2.0] Hz\n","\n","Class Labels (0-indexed)----------------------------------------------\n","  0: WALKING\n","  1: WALKING_UPSTAIRS\n","  2: WALKING_DOWNSTAIRS\n","  3: SITTING\n","  4: STANDING\n","  5: LAYING\n","\n","======================================================================\n","✓ Configuration saved to configs/windows.json\n","✓ Preprocessed data saved to data/*.npy\n","✓ Split info saved to data/split_info.csv\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["step 2"],"metadata":{"id":"c5OfVEsEFJ5z"}},{"cell_type":"code","source":["import os\n","import json\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader\n","from sklearn.metrics import accuracy_score, f1_score\n","import pickle\n","import random\n","\n","random.seed(42)\n","np.random.seed(42)\n","torch.manual_seed(42)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(42)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","os.makedirs('models', exist_ok=True)\n","os.makedirs('logs', exist_ok=True)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","try:\n","    import cupy as cp\n","    from cuml.neighbors import KNeighborsClassifier as cuKNN\n","    from cuml.ensemble import RandomForestClassifier as cuRF\n","    use_gpu_ml = True\n","    print(\"✓ cuML available for GPU-accelerated KNN/RF\")\n","except Exception as e:\n","    use_gpu_ml = False\n","    raise RuntimeError(\"cuML not available. Install with: pip install -q cupy-cuda12x cuml-cu12\")\n","\n","print(\"Loading data...\")\n","train_x = np.load('data/train_x.npy')\n","train_y = np.load('data/train_y.npy')\n","val_x = np.load('data/val_x.npy')\n","val_y = np.load('data/val_y.npy')\n","test_x = np.load('data/test_x.npy')\n","test_y = np.load('data/test_y.npy')\n","\n","with open('configs/windows.json', 'r') as f:\n","    config = json.load(f)\n","\n","n_classes = config['n_classes']\n","n_samples, seq_len, n_channels = train_x.shape\n","\n","train_x_flat = train_x.reshape(len(train_x), -1).astype(np.float32)\n","val_x_flat = val_x.reshape(len(val_x), -1).astype(np.float32)\n","test_x_flat = test_x.reshape(len(test_x), -1).astype(np.float32)\n","\n","metrics = []\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"MODEL TRAINING\")\n","print(\"=\" * 70)\n","\n","print(\"\\n[1/6] Training KNN (GPU)...\")\n","Xtr_cp = cp.asarray(train_x_flat)\n","ytr_cp = cp.asarray(train_y.astype(np.int32))\n","Xva_cp = cp.asarray(val_x_flat)\n","Xte_cp = cp.asarray(test_x_flat)\n","\n","knn = cuKNN(n_neighbors=5, algorithm='brute', metric='euclidean')\n","knn.fit(Xtr_cp, ytr_cp)\n","\n","val_pred = cp.asnumpy(knn.predict(Xva_cp))\n","val_acc = accuracy_score(val_y, val_pred)\n","val_f1 = f1_score(val_y, val_pred, average='macro')\n","\n","test_pred = cp.asnumpy(knn.predict(Xte_cp))\n","test_acc = accuracy_score(test_y, test_pred)\n","test_f1 = f1_score(test_y, test_pred, average='macro')\n","\n","print(f\"  Val  - Accuracy: {val_acc:.4f}, Macro-F1: {val_f1:.4f}\")\n","print(f\"  Test - Accuracy: {test_acc:.4f}, Macro-F1: {test_f1:.4f}\")\n","\n","with open('models/knn_cuml.pkl', 'wb') as f:\n","    pickle.dump(knn, f)\n","metrics.append({'model': 'KNN_GPU', 'val_accuracy': val_acc, 'val_macro_f1': val_f1,\n","                'test_accuracy': test_acc, 'test_macro_f1': test_f1})\n","\n","print(\"\\n[2/6] Training RandomForest (GPU)...\")\n","rf = cuRF(n_estimators=100, max_depth=20, random_state=42)\n","rf.fit(Xtr_cp, ytr_cp)\n","\n","val_pred = cp.asnumpy(rf.predict(Xva_cp))\n","val_acc = accuracy_score(val_y, val_pred)\n","val_f1 = f1_score(val_y, val_pred, average='macro')\n","\n","test_pred = cp.asnumpy(rf.predict(Xte_cp))\n","test_acc = accuracy_score(test_y, test_pred)\n","test_f1 = f1_score(test_y, test_pred, average='macro')\n","\n","print(f\"  Val  - Accuracy: {val_acc:.4f}, Macro-F1: {val_f1:.4f}\")\n","print(f\"  Test - Accuracy: {test_acc:.4f}, Macro-F1: {test_f1:.4f}\")\n","\n","with open('models/rf_cuml.pkl', 'wb') as f:\n","    pickle.dump(rf, f)\n","metrics.append({'model': 'RandomForest_GPU', 'val_accuracy': val_acc, 'val_macro_f1': val_f1,\n","                'test_accuracy': test_acc, 'test_macro_f1': test_f1})\n","\n","class TransformerModel(nn.Module):\n","    def __init__(self, input_dim, num_classes, d_model=64, nhead=4, num_layers=2):\n","        super().__init__()\n","        self.embedding = nn.Linear(input_dim, d_model)\n","        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,\n","                                                     dim_feedforward=256, batch_first=True)\n","        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n","        self.fc = nn.Linear(d_model, num_classes)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        x = self.transformer(x)\n","        x = x.mean(dim=1)\n","        return self.fc(x)\n","\n","print(\"\\n[3/6] Training TST (Transformer)...\")\n","tst_model = TransformerModel(n_channels, n_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(tst_model.parameters(), lr=0.001)\n","\n","train_dataset = TensorDataset(torch.FloatTensor(train_x), torch.LongTensor(train_y))\n","val_dataset = TensorDataset(torch.FloatTensor(val_x), torch.LongTensor(val_y))\n","test_dataset = TensorDataset(torch.FloatTensor(test_x), torch.LongTensor(test_y))\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n","\n","for epoch in range(10):\n","    tst_model.train()\n","    for batch_x, batch_y in train_loader:\n","        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n","        optimizer.zero_grad()\n","        outputs = tst_model(batch_x)\n","        loss = criterion(outputs, batch_y)\n","        loss.backward()\n","        optimizer.step()\n","\n","tst_model.eval()\n","val_preds, test_preds = [], []\n","with torch.no_grad():\n","    for batch_x, _ in val_loader:\n","        outputs = tst_model(batch_x.to(device))\n","        val_preds.append(outputs.argmax(dim=1).cpu())\n","    for batch_x, _ in test_loader:\n","        outputs = tst_model(batch_x.to(device))\n","        test_preds.append(outputs.argmax(dim=1).cpu())\n","\n","val_pred = torch.cat(val_preds).numpy()\n","test_pred = torch.cat(test_preds).numpy()\n","\n","val_acc = accuracy_score(val_y, val_pred)\n","val_f1 = f1_score(val_y, val_pred, average='macro')\n","test_acc = accuracy_score(test_y, test_pred)\n","test_f1 = f1_score(test_y, test_pred, average='macro')\n","\n","print(f\"  Val  - Accuracy: {val_acc:.4f}, Macro-F1: {val_f1:.4f}\")\n","print(f\"  Test - Accuracy: {test_acc:.4f}, Macro-F1: {test_f1:.4f}\")\n","\n","torch.save(tst_model.state_dict(), 'models/tst.pt')\n","metrics.append({'model': 'TST', 'val_accuracy': val_acc, 'val_macro_f1': val_f1,\n","                'test_accuracy': test_acc, 'test_macro_f1': test_f1})\n","\n","class MiniROCKET(nn.Module):\n","    def __init__(self, input_channels, num_classes, num_kernels=1000):\n","        super().__init__()\n","        self.kernels = nn.Parameter(torch.randn(num_kernels, input_channels, 9))\n","        self.fc = nn.Linear(num_kernels * 2, num_classes)\n","\n","    def forward(self, x):\n","        x = x.transpose(1, 2)\n","        conv_out = torch.nn.functional.conv1d(x, self.kernels, padding=4)\n","        ppv = (conv_out > 0).float().mean(dim=2)\n","        mx = conv_out.amax(dim=2)\n","        features = torch.cat([ppv, mx], dim=1)\n","        return self.fc(features)\n","\n","print(\"\\n[4/6] Training MiniROCKET...\")\n","mini_model = MiniROCKET(n_channels, n_classes).to(device)\n","optimizer = optim.Adam(mini_model.parameters(), lr=0.001)\n","\n","for epoch in range(10):\n","    mini_model.train()\n","    for batch_x, batch_y in train_loader:\n","        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n","        optimizer.zero_grad()\n","        outputs = mini_model(batch_x)\n","        loss = criterion(outputs, batch_y)\n","        loss.backward()\n","        optimizer.step()\n","\n","mini_model.eval()\n","val_preds, test_preds = [], []\n","with torch.no_grad():\n","    for batch_x, _ in val_loader:\n","        outputs = mini_model(batch_x.to(device))\n","        val_preds.append(outputs.argmax(dim=1).cpu())\n","    for batch_x, _ in test_loader:\n","        outputs = mini_model(batch_x.to(device))\n","        test_preds.append(outputs.argmax(dim=1).cpu())\n","\n","val_pred = torch.cat(val_preds).numpy()\n","test_pred = torch.cat(test_preds).numpy()\n","\n","val_acc = accuracy_score(val_y, val_pred)\n","val_f1 = f1_score(val_y, val_pred, average='macro')\n","test_acc = accuracy_score(test_y, test_pred)\n","test_f1 = f1_score(test_y, test_pred, average='macro')\n","\n","print(f\"  Val  - Accuracy: {val_acc:.4f}, Macro-F1: {val_f1:.4f}\")\n","print(f\"  Test - Accuracy: {test_acc:.4f}, Macro-F1: {test_f1:.4f}\")\n","\n","torch.save(mini_model.state_dict(), 'models/minirocket.pt')\n","metrics.append({'model': 'MiniROCKET', 'val_accuracy': val_acc, 'val_macro_f1': val_f1,\n","                'test_accuracy': test_acc, 'test_macro_f1': test_f1})\n","\n","class MultiROCKET(nn.Module):\n","    def __init__(self, input_channels, num_classes, num_kernels=2000):\n","        super().__init__()\n","        self.num_kernels = num_kernels\n","        self.kernels = nn.Parameter(torch.randn(num_kernels, input_channels, 9))\n","        dilations = torch.randint(1, 4, (num_kernels,))\n","        self.register_buffer('dilations', dilations)\n","        self.fc = nn.Linear(num_kernels * 2, num_classes)\n","\n","    def forward(self, x):\n","        x = x.transpose(1, 2)\n","        features_list = []\n","        for d in [1, 2, 3]:\n","            mask = self.dilations == d\n","            if mask.sum() > 0:\n","                kernels_d = self.kernels[mask]\n","                conv_out = torch.nn.functional.conv1d(x, kernels_d, padding=4*d, dilation=d)\n","                ppv = (conv_out > 0).float().mean(dim=2)\n","                mx = conv_out.amax(dim=2)\n","                features_list.append(torch.cat([ppv, mx], dim=1))\n","        features = torch.cat(features_list, dim=1)\n","        return self.fc(features)\n","\n","print(\"\\n[5/6] Training MultiROCKET...\")\n","multi_model = MultiROCKET(n_channels, n_classes).to(device)\n","optimizer = optim.Adam(multi_model.parameters(), lr=0.001)\n","\n","for epoch in range(10):\n","    multi_model.train()\n","    for batch_x, batch_y in train_loader:\n","        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n","        optimizer.zero_grad()\n","        outputs = multi_model(batch_x)\n","        loss = criterion(outputs, batch_y)\n","        loss.backward()\n","        optimizer.step()\n","\n","multi_model.eval()\n","val_preds, test_preds = [], []\n","with torch.no_grad():\n","    for batch_x, _ in val_loader:\n","        outputs = multi_model(batch_x.to(device))\n","        val_preds.append(outputs.argmax(dim=1).cpu())\n","    for batch_x, _ in test_loader:\n","        outputs = multi_model(batch_x.to(device))\n","        test_preds.append(outputs.argmax(dim=1).cpu())\n","\n","val_pred = torch.cat(val_preds).numpy()\n","test_pred = torch.cat(test_preds).numpy()\n","\n","val_acc = accuracy_score(val_y, val_pred)\n","val_f1 = f1_score(val_y, val_pred, average='macro')\n","test_acc = accuracy_score(test_y, test_pred)\n","test_f1 = f1_score(test_y, test_pred, average='macro')\n","\n","print(f\"  Val  - Accuracy: {val_acc:.4f}, Macro-F1: {val_f1:.4f}\")\n","print(f\"  Test - Accuracy: {test_acc:.4f}, Macro-F1: {test_f1:.4f}\")\n","\n","torch.save(multi_model.state_dict(), 'models/multirocket.pt')\n","metrics.append({'model': 'MultiROCKET', 'val_accuracy': val_acc, 'val_macro_f1': val_f1,\n","                'test_accuracy': test_acc, 'test_macro_f1': test_f1})\n","\n","class InceptionModule(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n","        self.conv3 = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1)\n","        self.conv5 = nn.Conv1d(in_channels, out_channels, kernel_size=5, padding=2)\n","        self.pool = nn.Sequential(nn.MaxPool1d(3, stride=1, padding=1),\n","                                  nn.Conv1d(in_channels, out_channels, kernel_size=1))\n","        self.bn = nn.BatchNorm1d(out_channels * 4)\n","\n","    def forward(self, x):\n","        x1 = self.conv1(x)\n","        x2 = self.conv3(x)\n","        x3 = self.conv5(x)\n","        x4 = self.pool(x)\n","        out = torch.cat([x1, x2, x3, x4], dim=1)\n","        return torch.relu(self.bn(out))\n","\n","class InceptionTime(nn.Module):\n","    def __init__(self, input_channels, num_classes):\n","        super().__init__()\n","        self.inception1 = InceptionModule(input_channels, 32)\n","        self.inception2 = InceptionModule(128, 64)\n","        self.gap = nn.AdaptiveAvgPool1d(1)\n","        self.fc = nn.Linear(256, num_classes)\n","\n","    def forward(self, x):\n","        x = x.transpose(1, 2)\n","        x = self.inception1(x)\n","        x = self.inception2(x)\n","        x = self.gap(x).squeeze(-1)\n","        return self.fc(x)\n","\n","print(\"\\n[6/6] Training InceptionTime...\")\n","inception_model = InceptionTime(n_channels, n_classes).to(device)\n","optimizer = optim.Adam(inception_model.parameters(), lr=0.001)\n","\n","for epoch in range(10):\n","    inception_model.train()\n","    for batch_x, batch_y in train_loader:\n","        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n","        optimizer.zero_grad()\n","        outputs = inception_model(batch_x)\n","        loss = criterion(outputs, batch_y)\n","        loss.backward()\n","        optimizer.step()\n","\n","inception_model.eval()\n","val_preds, test_preds = [], []\n","with torch.no_grad():\n","    for batch_x, _ in val_loader:\n","        outputs = inception_model(batch_x.to(device))\n","        val_preds.append(outputs.argmax(dim=1).cpu())\n","    for batch_x, _ in test_loader:\n","        outputs = inception_model(batch_x.to(device))\n","        test_preds.append(outputs.argmax(dim=1).cpu())\n","\n","val_pred = torch.cat(val_preds).numpy()\n","test_pred = torch.cat(test_preds).numpy()\n","\n","val_acc = accuracy_score(val_y, val_pred)\n","val_f1 = f1_score(val_y, val_pred, average='macro')\n","test_acc = accuracy_score(test_y, test_pred)\n","test_f1 = f1_score(test_y, test_pred, average='macro')\n","\n","print(f\"  Val  - Accuracy: {val_acc:.4f}, Macro-F1: {val_f1:.4f}\")\n","print(f\"  Test - Accuracy: {test_acc:.4f}, Macro-F1: {test_f1:.4f}\")\n","\n","torch.save(inception_model.state_dict(), 'models/inceptiontime.pt')\n","metrics.append({'model': 'InceptionTime', 'val_accuracy': val_acc, 'val_macro_f1': val_f1,\n","                'test_accuracy': test_acc, 'test_macro_f1': test_f1})\n","\n","metrics_df = pd.DataFrame(metrics)\n","metrics_df.to_csv('logs/train_metrics.csv', index=False)\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"TRAINING SUMMARY\")\n","print(\"=\" * 70)\n","print(f\"{'Model':<20} {'Val Acc':<10} {'Val F1':<10} {'Test Acc':<10} {'Test F1':<10}\")\n","print(\"-\" * 70)\n","for _, row in metrics_df.iterrows():\n","    print(f\"{row['model']:<20} {row['val_accuracy']:.4f}     {row['val_macro_f1']:.4f}     \"\n","          f\"{row['test_accuracy']:.4f}      {row['test_macro_f1']:.4f}\")\n","print(\"\\n\" + \"=\" * 70)\n","print(\"✓ Models saved to models/\")\n","print(\"✓ Training metrics saved to logs/train_metrics.csv\")\n","print(\"✓ Random seed: 42 (fixed)\")\n","print(\"=\" * 70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fN0hYH31EOpJ","executionInfo":{"status":"ok","timestamp":1762163558564,"user_tz":0,"elapsed":31984,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"2dd159de-b200-4a95-8949-96acb03e697f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","✓ cuML available for GPU-accelerated KNN/RF\n","Loading data...\n","\n","======================================================================\n","MODEL TRAINING\n","======================================================================\n","\n","[1/6] Training KNN (GPU)...\n","  Val  - Accuracy: 0.7518, Macro-F1: 0.7347\n","  Test - Accuracy: 0.6698, Macro-F1: 0.6555\n","\n","[2/6] Training RandomForest (GPU)...\n","  Val  - Accuracy: 0.9445, Macro-F1: 0.9445\n","  Test - Accuracy: 0.8483, Macro-F1: 0.8461\n","\n","[3/6] Training TST (Transformer)...\n","  Val  - Accuracy: 0.9378, Macro-F1: 0.9314\n","  Test - Accuracy: 0.8799, Macro-F1: 0.8748\n","\n","[4/6] Training MiniROCKET...\n","  Val  - Accuracy: 0.9733, Macro-F1: 0.9740\n","  Test - Accuracy: 0.9287, Macro-F1: 0.9300\n","\n","[5/6] Training MultiROCKET...\n","  Val  - Accuracy: 0.9761, Macro-F1: 0.9766\n","  Test - Accuracy: 0.9406, Macro-F1: 0.9411\n","\n","[6/6] Training InceptionTime...\n","  Val  - Accuracy: 0.9783, Macro-F1: 0.9788\n","  Test - Accuracy: 0.9369, Macro-F1: 0.9371\n","\n","======================================================================\n","TRAINING SUMMARY\n","======================================================================\n","Model                Val Acc    Val F1     Test Acc   Test F1   \n","----------------------------------------------------------------------\n","KNN_GPU              0.7518     0.7347     0.6698      0.6555\n","RandomForest_GPU     0.9445     0.9445     0.8483      0.8461\n","TST                  0.9378     0.9314     0.8799      0.8748\n","MiniROCKET           0.9733     0.9740     0.9287      0.9300\n","MultiROCKET          0.9761     0.9766     0.9406      0.9411\n","InceptionTime        0.9783     0.9788     0.9369      0.9371\n","\n","======================================================================\n","✓ Models saved to models/\n","✓ Training metrics saved to logs/train_metrics.csv\n","✓ Random seed: 42 (fixed)\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["step 3"],"metadata":{"id":"3sOSfV2YFL5P"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import pickle\n","import cupy as cp\n","from abc import ABC, abstractmethod\n","\n","USE_GPU_ONLY = True\n","if USE_GPU_ONLY:\n","    if not torch.cuda.is_available():\n","        raise RuntimeError(\"Step 3 要求 GPU 推理，但当前未检测到 CUDA。\")\n","    if cp.cuda.runtime.getDeviceCount() < 1:\n","        raise RuntimeError(\"未检测到可用的 CUDA 设备（CuPy）。\")\n","    cp.cuda.Device(0).use()\n","    torch.cuda.set_device(0)\n","device = torch.device('cuda')\n","\n","class InferenceAdapter(ABC):\n","    def __init__(self, model_name):\n","        self.model_name = model_name\n","        self.model = None\n","        self.warmed_up = False\n","        self.expected_shape = None\n","\n","    def _validate(self, X, expect_channels=None, dtype=np.float32):\n","        X = np.asarray(X)\n","        if X.ndim != 3:\n","            raise ValueError(f\"期望 X 形状 [B,T,C]，实际 {X.shape}\")\n","        if self.expected_shape is not None and tuple(X.shape) != self.expected_shape:\n","            raise ValueError(f\"输入形状漂移：期望 {self.expected_shape}，实际 {X.shape}\")\n","        if expect_channels is not None and X.shape[2] != expect_channels:\n","            raise ValueError(f\"C 维不一致：期望 {expect_channels}，实际 {X.shape[2]}\")\n","        if X.dtype != dtype:\n","            X = X.astype(dtype, copy=False)\n","        return X\n","\n","    @abstractmethod\n","    def load_model(self):\n","        pass\n","\n","    @abstractmethod\n","    def infer_one_batch(self, X):\n","        pass\n","\n","    def warmup(self, input_shape, n_warmup=20):\n","        self.expected_shape = tuple(input_shape)\n","        dummy_input = np.random.randn(*self.expected_shape).astype(np.float32)\n","        for _ in range(n_warmup):\n","            _ = self.infer_one_batch(dummy_input)\n","        self.warmed_up = True\n","\n","    def infer_repeated(self, X, n_repeat=100):\n","        results = []\n","        for _ in range(n_repeat):\n","            result = self.infer_one_batch(X)\n","            results.append(result)\n","        return results\n","\n","\n","class KNNAdapter(InferenceAdapter):\n","    def __init__(self, n_channels=9):\n","        super().__init__(\"KNN_GPU\")\n","        self.n_channels = n_channels\n","        self.expected_flat = None\n","        self.load_model()\n","\n","    def load_model(self):\n","        with open('models/knn_cuml.pkl', 'rb') as f:\n","            self.model = pickle.load(f)\n","        self.expected_flat = getattr(self.model, \"n_features_in_\", None) or getattr(self.model, \"n_cols\", None)\n","\n","    def infer_one_batch(self, X):\n","        X = self._validate(X, self.n_channels)\n","        B, T, C = X.shape\n","        X_flat = X.reshape(B, -1)\n","        if self.expected_flat is not None and X_flat.shape[1] != self.expected_flat:\n","            raise ValueError(f\"KNN 输入维度与训练不一致：期望 {self.expected_flat}，实际 {X_flat.shape[1]}\")\n","        with cp.cuda.Device(0):\n","            X_cp = cp.asarray(X_flat)\n","            probs_cp = self.model.predict_proba(X_cp)\n","        cp.cuda.runtime.deviceSynchronize()\n","        probs = cp.asnumpy(probs_cp)\n","        return probs.astype(np.float32, copy=False)\n","\n","\n","class RandomForestAdapter(InferenceAdapter):\n","    def __init__(self, n_channels=9):\n","        super().__init__(\"RandomForest_GPU\")\n","        self.n_channels = n_channels\n","        self.expected_flat = None\n","        self.load_model()\n","\n","    def load_model(self):\n","        with open('models/rf_cuml.pkl', 'rb') as f:\n","            self.model = pickle.load(f)\n","        self.expected_flat = getattr(self.model, \"n_features_in_\", None) or getattr(self.model, \"n_cols\", None)\n","\n","    def infer_one_batch(self, X):\n","        X = self._validate(X, self.n_channels)\n","        B, T, C = X.shape\n","        X_flat = X.reshape(B, -1)\n","        if self.expected_flat is not None and X_flat.shape[1] != self.expected_flat:\n","            raise ValueError(f\"RandomForest 输入维度与训练不一致：期望 {self.expected_flat}，实际 {X_flat.shape[1]}\")\n","        with cp.cuda.Device(0):\n","            X_cp = cp.asarray(X_flat)\n","            probs_cp = self.model.predict_proba(X_cp)\n","        cp.cuda.runtime.deviceSynchronize()\n","        probs = cp.asnumpy(probs_cp)\n","        return probs.astype(np.float32, copy=False)\n","\n","\n","class TransformerModel(nn.Module):\n","    def __init__(self, input_dim, num_classes, d_model=64, nhead=4, num_layers=2):\n","        super().__init__()\n","        self.embedding = nn.Linear(input_dim, d_model)\n","        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,\n","                                                     dim_feedforward=256, batch_first=True)\n","        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n","        self.fc = nn.Linear(d_model, num_classes)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        x = self.transformer(x)\n","        x = x.mean(dim=1)\n","        return self.fc(x)\n","\n","\n","class TSTAdapter(InferenceAdapter):\n","    def __init__(self, n_channels=9, n_classes=6):\n","        super().__init__(\"TST\")\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.load_model()\n","\n","    def load_model(self):\n","        self.model = TransformerModel(self.n_channels, self.n_classes).to(device)\n","        self.model.load_state_dict(torch.load('models/tst.pt', map_location=device))\n","        self.model.eval()\n","\n","    def infer_one_batch(self, X):\n","        X = self._validate(X, self.n_channels)\n","        X_tensor = torch.FloatTensor(X).to(device)\n","        with torch.inference_mode():\n","            logits = self.model(X_tensor)\n","            probs = torch.softmax(logits, dim=1)\n","        torch.cuda.synchronize()\n","        return probs.detach().cpu().numpy().astype(np.float32, copy=False)\n","\n","\n","class MiniROCKET(nn.Module):\n","    def __init__(self, input_channels, num_classes, num_kernels=1000):\n","        super().__init__()\n","        self.kernels = nn.Parameter(torch.randn(num_kernels, input_channels, 9))\n","        self.fc = nn.Linear(num_kernels * 2, num_classes)\n","\n","    def forward(self, x):\n","        x = x.transpose(1, 2).contiguous()\n","        conv_out = torch.nn.functional.conv1d(x, self.kernels, padding=4)\n","        ppv = (conv_out > 0).float().mean(dim=2)\n","        mx = conv_out.amax(dim=2)\n","        features = torch.cat([ppv, mx], dim=1)\n","        return self.fc(features)\n","\n","\n","class MiniROCKETAdapter(InferenceAdapter):\n","    def __init__(self, n_channels=9, n_classes=6):\n","        super().__init__(\"MiniROCKET\")\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.load_model()\n","\n","    def load_model(self):\n","        self.model = MiniROCKET(self.n_channels, self.n_classes).to(device)\n","        self.model.load_state_dict(torch.load('models/minirocket.pt', map_location=device))\n","        self.model.eval()\n","\n","    def infer_one_batch(self, X):\n","        X = self._validate(X, self.n_channels)\n","        X_tensor = torch.FloatTensor(X).to(device)\n","        with torch.inference_mode():\n","            logits = self.model(X_tensor)\n","            probs = torch.softmax(logits, dim=1)\n","        torch.cuda.synchronize()\n","        return probs.detach().cpu().numpy().astype(np.float32, copy=False)\n","\n","\n","class MultiROCKET(nn.Module):\n","    def __init__(self, input_channels, num_classes, num_kernels=2000):\n","        super().__init__()\n","        self.num_kernels = num_kernels\n","        self.kernels = nn.Parameter(torch.randn(num_kernels, input_channels, 9))\n","        dilations = torch.randint(1, 4, (num_kernels,))\n","        self.register_buffer('dilations', dilations)\n","        self.fc = nn.Linear(num_kernels * 2, num_classes)\n","\n","    def forward(self, x):\n","        x = x.transpose(1, 2).contiguous()\n","        features_list = []\n","        for d in [1, 2, 3]:\n","            mask = self.dilations == d\n","            if mask.any():\n","                kernels_d = self.kernels[mask]\n","                conv_out = torch.nn.functional.conv1d(x, kernels_d, padding=4*d, dilation=d)\n","                ppv = (conv_out > 0).float().mean(dim=2)\n","                mx = conv_out.amax(dim=2)\n","                features_list.append(torch.cat([ppv, mx], dim=1))\n","        features = torch.cat(features_list, dim=1)\n","        return self.fc(features)\n","\n","\n","class MultiROCKETAdapter(InferenceAdapter):\n","    def __init__(self, n_channels=9, n_classes=6):\n","        super().__init__(\"MultiROCKET\")\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.load_model()\n","\n","    def load_model(self):\n","        self.model = MultiROCKET(self.n_channels, self.n_classes).to(device)\n","        self.model.load_state_dict(torch.load('models/multirocket.pt', map_location=device))\n","        self.model.eval()\n","\n","    def infer_one_batch(self, X):\n","        X = self._validate(X, self.n_channels)\n","        X_tensor = torch.FloatTensor(X).to(device)\n","        with torch.inference_mode():\n","            logits = self.model(X_tensor)\n","            probs = torch.softmax(logits, dim=1)\n","        torch.cuda.synchronize()\n","        return probs.detach().cpu().numpy().astype(np.float32, copy=False)\n","\n","\n","class InceptionModule(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n","        self.conv3 = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1)\n","        self.conv5 = nn.Conv1d(in_channels, out_channels, kernel_size=5, padding=2)\n","        self.pool = nn.Sequential(nn.MaxPool1d(3, stride=1, padding=1),\n","                                  nn.Conv1d(in_channels, out_channels, kernel_size=1))\n","        self.bn = nn.BatchNorm1d(out_channels * 4)\n","\n","    def forward(self, x):\n","        x1 = self.conv1(x)\n","        x2 = self.conv3(x)\n","        x3 = self.conv5(x)\n","        x4 = self.pool(x)\n","        out = torch.cat([x1, x2, x3, x4], dim=1)\n","        return torch.relu(self.bn(out))\n","\n","\n","class InceptionTime(nn.Module):\n","    def __init__(self, input_channels, num_classes):\n","        super().__init__()\n","        self.inception1 = InceptionModule(input_channels, 32)\n","        self.inception2 = InceptionModule(128, 64)\n","        self.gap = nn.AdaptiveAvgPool1d(1)\n","        self.fc = nn.Linear(256, num_classes)\n","\n","    def forward(self, x):\n","        x = x.transpose(1, 2).contiguous()\n","        x = self.inception1(x)\n","        x = self.inception2(x)\n","        x = self.gap(x).squeeze(-1)\n","        return self.fc(x)\n","\n","\n","class InceptionTimeAdapter(InferenceAdapter):\n","    def __init__(self, n_channels=9, n_classes=6):\n","        super().__init__(\"InceptionTime\")\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.load_model()\n","\n","    def load_model(self):\n","        self.model = InceptionTime(self.n_channels, self.n_classes).to(device)\n","        self.model.load_state_dict(torch.load('models/inceptiontime.pt', map_location=device))\n","        self.model.eval()\n","\n","    def infer_one_batch(self, X):\n","        X = self._validate(X, self.n_channels)\n","        X_tensor = torch.FloatTensor(X).to(device)\n","        with torch.inference_mode():\n","            logits = self.model(X_tensor)\n","            probs = torch.softmax(logits, dim=1)\n","        torch.cuda.synchronize()\n","        return probs.detach().cpu().numpy().astype(np.float32, copy=False)\n","\n","\n","def create_adapters():\n","    adapters = {\n","        'KNN': KNNAdapter(),\n","        'RandomForest': RandomForestAdapter(),\n","        'TST': TSTAdapter(),\n","        'MiniROCKET': MiniROCKETAdapter(),\n","        'MultiROCKET': MultiROCKETAdapter(),\n","        'InceptionTime': InceptionTimeAdapter()\n","    }\n","    return adapters\n","\n","\n","if __name__ == \"__main__\":\n","    test_x = np.load('data/test_x.npy')\n","    batch_size = 32\n","    test_batch = test_x[:batch_size]\n","\n","    adapters = create_adapters()\n","\n","    print(\"=\" * 70)\n","    print(\"INFERENCE ADAPTER TEST\")\n","    print(\"=\" * 70)\n","    print(f\"\\nInput shape: {test_batch.shape}\")\n","    print(f\"Device: {device}\")\n","\n","    for name, adapter in adapters.items():\n","        print(f\"\\n[{name}]\")\n","\n","        print(\"  Warming up...\")\n","        adapter.warmup(test_batch.shape)\n","\n","        print(\"  Running inference...\")\n","        probs = adapter.infer_one_batch(test_batch)\n","        preds = np.argmax(probs, axis=1)\n","\n","        print(f\"  Output shape: {probs.shape}\")\n","        print(f\"  Predictions: {preds[:10]}\")\n","        print(f\"  Prob range: [{probs.min():.4f}, {probs.max():.4f}]\")\n","\n","    print(\"\\n\" + \"=\" * 70)\n","    print(\"✓ All adapters tested successfully\")\n","    print(\"=\" * 70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aR-j-y8TEPsQ","executionInfo":{"status":"ok","timestamp":1762163559254,"user_tz":0,"elapsed":661,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"d65d6c2d-7261-44ab-9b96-27857f2a515b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","INFERENCE ADAPTER TEST\n","======================================================================\n","\n","Input shape: (32, 128, 9)\n","Device: cuda\n","\n","[KNN]\n","  Warming up...\n","  Running inference...\n","  Output shape: (32, 6)\n","  Predictions: [4 4 4 4 4 4 4 4 4 4]\n","  Prob range: [0.0000, 1.0000]\n","\n","[RandomForest]\n","  Warming up...\n","  Running inference...\n","  Output shape: (32, 6)\n","  Predictions: [4 4 4 4 4 4 4 4 4 4]\n","  Prob range: [0.0000, 1.0000]\n","\n","[TST]\n","  Warming up...\n","  Running inference...\n","  Output shape: (32, 6)\n","  Predictions: [4 4 4 4 4 4 4 4 4 4]\n","  Prob range: [0.0000, 0.9985]\n","\n","[MiniROCKET]\n","  Warming up...\n","  Running inference...\n","  Output shape: (32, 6)\n","  Predictions: [4 4 4 4 4 4 4 4 4 4]\n","  Prob range: [0.0000, 0.9987]\n","\n","[MultiROCKET]\n","  Warming up...\n","  Running inference...\n","  Output shape: (32, 6)\n","  Predictions: [4 4 4 4 4 4 4 4 4 4]\n","  Prob range: [0.0000, 1.0000]\n","\n","[InceptionTime]\n","  Warming up...\n","  Running inference...\n","  Output shape: (32, 6)\n","  Predictions: [4 4 4 4 4 4 4 4 4 4]\n","  Prob range: [0.0000, 0.9946]\n","\n","======================================================================\n","✓ All adapters tested successfully\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["step 4"],"metadata":{"id":"OZA7mu9IFNld"}},{"cell_type":"code","source":["import os\n","import json\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import pickle\n","from collections import defaultdict\n","\n","os.makedirs('logs', exist_ok=True)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","macs_counter = {'total': 0}\n","_outproj_called = defaultdict(bool)\n","\n","class TransformerModel(nn.Module):\n","    def __init__(self, input_dim, num_classes, d_model=64, nhead=4, num_layers=2):\n","        super().__init__()\n","        self.embedding = nn.Linear(input_dim, d_model)\n","        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,\n","                                                     dim_feedforward=256, batch_first=True)\n","        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n","        self.fc = nn.Linear(d_model, num_classes)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        x = self.transformer(x)\n","        x = x.mean(dim=1)\n","        return self.fc(x)\n","\n","class MiniROCKET(nn.Module):\n","    def __init__(self, input_channels, num_classes, num_kernels=1000):\n","        super().__init__()\n","        self.num_kernels = num_kernels\n","        self.input_channels = input_channels\n","        self.kernels = nn.Parameter(torch.randn(num_kernels, input_channels, 9))\n","        self.fc = nn.Linear(num_kernels * 2, num_classes)\n","\n","    def forward(self, x):\n","        x = x.transpose(1, 2).contiguous()\n","        conv_out = torch.nn.functional.conv1d(x, self.kernels, padding=4)\n","        ppv = (conv_out > 0).float().mean(dim=2)\n","        mx = conv_out.amax(dim=2)\n","        features = torch.cat([ppv, mx], dim=1)\n","        return self.fc(features)\n","\n","class MultiROCKET(nn.Module):\n","    def __init__(self, input_channels, num_classes, num_kernels=2000):\n","        super().__init__()\n","        self.num_kernels = num_kernels\n","        self.input_channels = input_channels\n","        self.kernels = nn.Parameter(torch.randn(num_kernels, input_channels, 9))\n","        dilations = torch.randint(1, 4, (num_kernels,))\n","        self.register_buffer('dilations', dilations)\n","        self.fc = nn.Linear(num_kernels * 2, num_classes)\n","\n","    def forward(self, x):\n","        x = x.transpose(1, 2).contiguous()\n","        features_list = []\n","        for d in [1, 2, 3]:\n","            mask = self.dilations == d\n","            if mask.any():\n","                kernels_d = self.kernels[mask]\n","                conv_out = torch.nn.functional.conv1d(x, kernels_d, padding=4*d, dilation=d)\n","                ppv = (conv_out > 0).float().mean(dim=2)\n","                mx = conv_out.amax(dim=2)\n","                features_list.append(torch.cat([ppv, mx], dim=1))\n","        features = torch.cat(features_list, dim=1)\n","        return self.fc(features)\n","\n","class InceptionModule(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n","        self.conv3 = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1)\n","        self.conv5 = nn.Conv1d(in_channels, out_channels, kernel_size=5, padding=2)\n","        self.pool = nn.Sequential(nn.MaxPool1d(3, stride=1, padding=1),\n","                                  nn.Conv1d(in_channels, out_channels, kernel_size=1))\n","        self.bn = nn.BatchNorm1d(out_channels * 4)\n","\n","    def forward(self, x):\n","        x1 = self.conv1(x)\n","        x2 = self.conv3(x)\n","        x3 = self.conv5(x)\n","        x4 = self.pool(x)\n","        out = torch.cat([x1, x2, x3, x4], dim=1)\n","        return torch.relu(self.bn(out))\n","\n","class InceptionTime(nn.Module):\n","    def __init__(self, input_channels, num_classes):\n","        super().__init__()\n","        self.inception1 = InceptionModule(input_channels, 32)\n","        self.inception2 = InceptionModule(128, 64)\n","        self.gap = nn.AdaptiveAvgPool1d(1)\n","        self.fc = nn.Linear(256, num_classes)\n","\n","    def forward(self, x):\n","        x = x.transpose(1, 2).contiguous()\n","        x = self.inception1(x)\n","        x = self.inception2(x)\n","        x = self.gap(x).squeeze(-1)\n","        return self.fc(x)\n","\n","test_x = np.load('data/test_x.npy')\n","batch_size = 32\n","test_batch = test_x[:batch_size]\n","\n","B, seq_len, n_channels = test_batch.shape\n","n_classes = 6\n","\n","def make_mark_out_proj(mha_id):\n","    def _mark_out_proj(m, x, y):\n","        _outproj_called[mha_id] = True\n","    return _mark_out_proj\n","\n","def count_conv1d(m, x, y):\n","    batch = y.size(0)\n","    kernel_size = m.kernel_size[0]\n","    in_ch = m.in_channels\n","    out_ch = m.out_channels\n","    out_size = y.size(2)\n","    groups = m.groups\n","    macs = batch * out_size * out_ch * (in_ch // groups) * kernel_size\n","    macs_counter['total'] += macs\n","\n","def count_linear(m, x, y):\n","    B = y.size(0)\n","    out_feat = m.out_features\n","    in_feat = m.in_features\n","    num_pos = y.numel() // (B * out_feat)\n","    macs = B * num_pos * in_feat * out_feat\n","    macs_counter['total'] += macs\n","\n","def count_batchnorm(m, x, y):\n","    batch = y.size(0)\n","    elements = y.numel() / batch\n","    macs = 2 * batch * elements\n","    macs_counter['total'] += macs\n","\n","def count_multihead_attention(m, x, y):\n","    if isinstance(m, nn.MultiheadAttention):\n","        B, N, d = x[0].size()\n","        H = m.num_heads\n","        d_k = d // H\n","        macs = 3 * B * N * d * d\n","        macs += 2 * B * H * N * N * d_k\n","        if not _outproj_called[id(m)]:\n","            macs += B * N * d * d\n","        macs_counter['total'] += macs\n","\n","def count_layernorm(m, x, y):\n","    batch = y.size(0)\n","    elements = y.numel() / batch\n","    macs = 5 * batch * elements\n","    macs_counter['total'] += macs\n","\n","def count_minirocket(m, x, y):\n","    if isinstance(m, MiniROCKET):\n","        B, T, C = x[0].shape\n","        ks = m.kernels.shape[2]\n","        L_out = T\n","        macs = B * L_out * m.num_kernels * C * ks\n","        macs_counter['total'] += macs\n","\n","def count_multirocket(m, x, y):\n","    if isinstance(m, MultiROCKET):\n","        B, T, C = x[0].shape\n","        ks = m.kernels.shape[2]\n","        for d in [1, 2, 3]:\n","            K_d = int((m.dilations == d).sum().item())\n","            if K_d > 0:\n","                L_out = T\n","                macs = B * L_out * K_d * C * ks\n","                macs_counter['total'] += macs\n","\n","def register_hooks(model):\n","    hooks = []\n","    for m in model.modules():\n","        if isinstance(m, nn.MultiheadAttention):\n","            hooks.append(m.out_proj.register_forward_hook(make_mark_out_proj(id(m))))\n","            hooks.append(m.register_forward_hook(count_multihead_attention))\n","        elif isinstance(m, nn.Conv1d):\n","            hooks.append(m.register_forward_hook(count_conv1d))\n","        elif isinstance(m, nn.Linear):\n","            hooks.append(m.register_forward_hook(count_linear))\n","        elif isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d)):\n","            hooks.append(m.register_forward_hook(count_batchnorm))\n","        elif isinstance(m, nn.LayerNorm):\n","            hooks.append(m.register_forward_hook(count_layernorm))\n","        elif isinstance(m, MiniROCKET):\n","            hooks.append(m.register_forward_hook(count_minirocket))\n","        elif isinstance(m, MultiROCKET):\n","            hooks.append(m.register_forward_hook(count_multirocket))\n","    return hooks\n","\n","models = {\n","    'TST': TransformerModel(n_channels, n_classes).to(device),\n","    'MiniROCKET': MiniROCKET(n_channels, n_classes).to(device),\n","    'MultiROCKET': MultiROCKET(n_channels, n_classes).to(device),\n","    'InceptionTime': InceptionTime(n_channels, n_classes).to(device)\n","}\n","\n","for name in models:\n","    models[name].load_state_dict(torch.load(f'models/{name.lower()}.pt', map_location=device))\n","    models[name].eval()\n","\n","results = []\n","\n","print(\"=\" * 70)\n","print(\"MACs CALCULATION\")\n","print(\"=\" * 70)\n","\n","for model_name, model in models.items():\n","    print(f\"\\n[{model_name}]\")\n","\n","    _outproj_called.clear()\n","    macs_counter['total'] = 0\n","    hooks = register_hooks(model)\n","\n","    X_tensor = torch.FloatTensor(test_batch).to(device)\n","    with torch.no_grad():\n","        _ = model(X_tensor)\n","\n","    for h in hooks:\n","        h.remove()\n","\n","    total_macs = macs_counter['total']\n","    macs_per_inf = total_macs / batch_size\n","\n","    print(f\"  Total MACs (B={batch_size}): {total_macs:,.0f}\")\n","    print(f\"  MACs per inference: {macs_per_inf:,.0f}\")\n","\n","    results.append({\n","        'model': model_name,\n","        'batch_size': batch_size,\n","        'total_macs': total_macs,\n","        'macs_per_inf': macs_per_inf,\n","        'method': 'forward_hook',\n","        'note': ''\n","    })\n","\n","print(f\"\\n[KNN]\")\n","d = seq_len * n_channels\n","n_train = len(np.load('data/train_x.npy'))\n","\n","macs_per_inf = 2 * d * n_train\n","total_macs = macs_per_inf * batch_size\n","\n","print(f\"  d={d}, N_train={n_train}\")\n","print(f\"  MACs per inference: {macs_per_inf:,.0f}\")\n","print(f\"  Formula: 2 * d * N_train (L2 distance computation)\")\n","\n","results.append({\n","    'model': 'KNN',\n","    'batch_size': batch_size,\n","    'total_macs': total_macs,\n","    'macs_per_inf': macs_per_inf,\n","    'method': 'analytical',\n","    'note': 'L2 distance brute-force'\n","})\n","\n","print(f\"\\n[RandomForest]\")\n","\n","with open('models/rf_cuml.pkl', 'rb') as f:\n","    rf_model = pickle.load(f)\n","\n","try:\n","    n_trees = getattr(rf_model, \"n_estimators\", getattr(rf_model, \"n_estimators_\", 100))\n","except:\n","    n_trees = 100\n","\n","avg_depth = 15\n","\n","print(f\"  n_trees={n_trees}, avg_depth≈{avg_depth} (conservative estimate)\")\n","\n","ops_per_inf = n_trees * avg_depth * 2\n","total_ops = ops_per_inf * batch_size\n","\n","print(f\"  Ops per inference: {ops_per_inf:,.0f}\")\n","print(f\"  Formula: n_trees * avg_depth * 2 (comparison converted to MAC-equiv)\")\n","\n","results.append({\n","    'model': 'RandomForest',\n","    'batch_size': batch_size,\n","    'total_macs': total_ops,\n","    'macs_per_inf': ops_per_inf,\n","    'method': 'analytical',\n","    'note': 'Threshold comparisons converted to MAC-equiv (×2)'\n","})\n","\n","df = pd.DataFrame(results)\n","df.to_csv('logs/macs_per_inf.csv', index=False)\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"MACs SUMMARY\")\n","print(\"=\" * 70)\n","print(f\"{'Model':<20} {'MACs/inf':<20} {'Method':<15}\")\n","print(\"-\" * 70)\n","for _, row in df.iterrows():\n","    print(f\"{row['model']:<20} {row['macs_per_inf']:>19,.0f} {row['method']:<15}\")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"CALCULATION METHODOLOGY\")\n","print(\"=\" * 70)\n","print(f\"\"\"\n","UNIT: MACs (Multiply-Accumulate operations)\n","  - 1 MAC = 1 multiply + 1 add\n","  - To convert to FLOPs: multiply by 2\n","\n","Deep Learning Models (forward_hook):\n","  Conv1d:            batch * out_size * out_ch * (in_ch/groups) * kernel_size\n","  Linear:            B * num_pos * in_feat * out_feat\n","                     where num_pos = y.numel() // (B * out_feat)\n","                     handles both (B, N, feat) and (B, feat) automatically\n","  BatchNorm:         2 * batch * elements (mean + variance normalization)\n","  LayerNorm:         5 * batch * elements (mean, variance, scale, shift)\n","  MultiheadAttention:\n","    - QKV projection: 3 * B * N * d * d (functional linear, not via Linear hook)\n","    - Attention:      2 * B * H * N * N * d_k (QK^T + Attn@V)\n","    - out_proj:       B * N * d * d (added if not counted by Linear hook)\n","    - Note: FFN counted separately by Linear hook\n","  MiniROCKET:        B * T * num_kernels * in_ch * 9\n","  MultiROCKET:       Sum over dilations [1,2,3] of B * T * K_d * in_ch * 9\n","\n","KNN (analytical approximation):\n","  2 * d * N_train\n","  Assumption: L2 distance = subtract + square + sum (≈2d MACs per pair)\n","  Brute-force search over all training samples\n","  d={d}, N_train={n_train}\n","  Note: Top-k maintenance overhead (N*log k comparisons) is negligible\n","\n","RandomForest (analytical approximation):\n","  n_trees * avg_depth * 2\n","  Assumption: Each node performs 1 threshold comparison\n","  Converted to MAC-equiv by multiplying by 2 for cross-model comparison\n","  avg_depth ≈ {avg_depth} (conservative estimate)\n","  n_trees={n_trees}\n","  Note: True comparison count = n_trees * avg_depth\n","\n","Input shape: {test_batch.shape} - [batch, seq_len, channels]\n","Batch size for measurement: {batch_size}\n","All MACs normalized to per-inference basis.\n","\n","Note: MaxPool, AdaptiveAvgPool, ReLU overheads not counted (negligible).\n","\"\"\")\n","\n","print(\"=\" * 70)\n","print(\"✓ MACs statistics saved to logs/macs_per_inf.csv\")\n","print(\"✓ Column 'macs_per_inf' represents MACs (not FLOPs)\")\n","print(\"=\" * 70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z4YgC_8eERA8","executionInfo":{"status":"ok","timestamp":1762163559367,"user_tz":0,"elapsed":83,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"77d4fcb8-42f7-4221-9d70-dc8d8dff4015"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","MACs CALCULATION\n","======================================================================\n","\n","[TST]\n","  Total MACs (B=32): 544,485,376\n","  MACs per inference: 17,015,168\n","\n","[MiniROCKET]\n","  Total MACs (B=32): 332,160,000\n","  MACs per inference: 10,380,000\n","\n","[MultiROCKET]\n","  Total MACs (B=32): 664,320,000\n","  MACs per inference: 20,760,000\n","\n","[InceptionTime]\n","  Total MACs (B=32): 350,535,680\n","  MACs per inference: 10,954,240\n","\n","[KNN]\n","  d=1152, N_train=5551\n","  MACs per inference: 12,789,504\n","  Formula: 2 * d * N_train (L2 distance computation)\n","\n","[RandomForest]\n","  n_trees=100, avg_depth≈15 (conservative estimate)\n","  Ops per inference: 3,000\n","  Formula: n_trees * avg_depth * 2 (comparison converted to MAC-equiv)\n","\n","======================================================================\n","MACs SUMMARY\n","======================================================================\n","Model                MACs/inf             Method         \n","----------------------------------------------------------------------\n","TST                           17,015,168 forward_hook   \n","MiniROCKET                    10,380,000 forward_hook   \n","MultiROCKET                   20,760,000 forward_hook   \n","InceptionTime                 10,954,240 forward_hook   \n","KNN                           12,789,504 analytical     \n","RandomForest                       3,000 analytical     \n","\n","======================================================================\n","CALCULATION METHODOLOGY\n","======================================================================\n","\n","UNIT: MACs (Multiply-Accumulate operations)\n","  - 1 MAC = 1 multiply + 1 add\n","  - To convert to FLOPs: multiply by 2\n","\n","Deep Learning Models (forward_hook):\n","  Conv1d:            batch * out_size * out_ch * (in_ch/groups) * kernel_size\n","  Linear:            B * num_pos * in_feat * out_feat\n","                     where num_pos = y.numel() // (B * out_feat)\n","                     handles both (B, N, feat) and (B, feat) automatically\n","  BatchNorm:         2 * batch * elements (mean + variance normalization)\n","  LayerNorm:         5 * batch * elements (mean, variance, scale, shift)\n","  MultiheadAttention:\n","    - QKV projection: 3 * B * N * d * d (functional linear, not via Linear hook)\n","    - Attention:      2 * B * H * N * N * d_k (QK^T + Attn@V)\n","    - out_proj:       B * N * d * d (added if not counted by Linear hook)\n","    - Note: FFN counted separately by Linear hook\n","  MiniROCKET:        B * T * num_kernels * in_ch * 9\n","  MultiROCKET:       Sum over dilations [1,2,3] of B * T * K_d * in_ch * 9\n","\n","KNN (analytical approximation):\n","  2 * d * N_train\n","  Assumption: L2 distance = subtract + square + sum (≈2d MACs per pair)\n","  Brute-force search over all training samples\n","  d=1152, N_train=5551\n","  Note: Top-k maintenance overhead (N*log k comparisons) is negligible\n","\n","RandomForest (analytical approximation):\n","  n_trees * avg_depth * 2\n","  Assumption: Each node performs 1 threshold comparison\n","  Converted to MAC-equiv by multiplying by 2 for cross-model comparison\n","  avg_depth ≈ 15 (conservative estimate)\n","  n_trees=100\n","  Note: True comparison count = n_trees * avg_depth\n","\n","Input shape: (32, 128, 9) - [batch, seq_len, channels]\n","Batch size for measurement: 32\n","All MACs normalized to per-inference basis.\n","\n","Note: MaxPool, AdaptiveAvgPool, ReLU overheads not counted (negligible).\n","\n","======================================================================\n","✓ MACs statistics saved to logs/macs_per_inf.csv\n","✓ Column 'macs_per_inf' represents MACs (not FLOPs)\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["step 5"],"metadata":{"id":"MgnA6KQrFPWR"}},{"cell_type":"code","source":["import os\n","import json\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import pickle\n","\n","os.makedirs('logs', exist_ok=True)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","class TransformerModel(nn.Module):\n","    def __init__(self, input_dim, num_classes, d_model=64, nhead=4, num_layers=2):\n","        super().__init__()\n","        self.embedding = nn.Linear(input_dim, d_model)\n","        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,\n","                                                     dim_feedforward=256, batch_first=True)\n","        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n","        self.fc = nn.Linear(d_model, num_classes)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        x = self.transformer(x)\n","        x = x.mean(dim=1)\n","        return self.fc(x)\n","\n","class MiniROCKET(nn.Module):\n","    def __init__(self, input_channels, num_classes, num_kernels=1000):\n","        super().__init__()\n","        self.num_kernels = num_kernels\n","        self.input_channels = input_channels\n","        self.kernels = nn.Parameter(torch.randn(num_kernels, input_channels, 9))\n","        self.fc = nn.Linear(num_kernels * 2, num_classes)\n","\n","    def forward(self, x):\n","        x = x.transpose(1, 2).contiguous()\n","        conv_out = torch.nn.functional.conv1d(x, self.kernels, padding=4)\n","        ppv = (conv_out > 0).float().mean(dim=2)\n","        mx = conv_out.amax(dim=2)\n","        features = torch.cat([ppv, mx], dim=1)\n","        return self.fc(features)\n","\n","class MultiROCKET(nn.Module):\n","    def __init__(self, input_channels, num_classes, num_kernels=2000):\n","        super().__init__()\n","        self.num_kernels = num_kernels\n","        self.input_channels = input_channels\n","        self.kernels = nn.Parameter(torch.randn(num_kernels, input_channels, 9))\n","        dilations = torch.randint(1, 4, (num_kernels,))\n","        self.register_buffer('dilations', dilations)\n","        self.fc = nn.Linear(num_kernels * 2, num_classes)\n","\n","    def forward(self, x):\n","        x = x.transpose(1, 2).contiguous()\n","        features_list = []\n","        for d in [1, 2, 3]:\n","            mask = self.dilations == d\n","            if mask.any():\n","                kernels_d = self.kernels[mask]\n","                conv_out = torch.nn.functional.conv1d(x, kernels_d, padding=4*d, dilation=d)\n","                ppv = (conv_out > 0).float().mean(dim=2)\n","                mx = conv_out.amax(dim=2)\n","                features_list.append(torch.cat([ppv, mx], dim=1))\n","        features = torch.cat(features_list, dim=1)\n","        return self.fc(features)\n","\n","class InceptionModule(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n","        self.conv3 = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1)\n","        self.conv5 = nn.Conv1d(in_channels, out_channels, kernel_size=5, padding=2)\n","        self.pool = nn.Sequential(nn.MaxPool1d(3, stride=1, padding=1),\n","                                  nn.Conv1d(in_channels, out_channels, kernel_size=1))\n","        self.bn = nn.BatchNorm1d(out_channels * 4)\n","\n","    def forward(self, x):\n","        x1 = self.conv1(x)\n","        x2 = self.conv3(x)\n","        x3 = self.conv5(x)\n","        x4 = self.pool(x)\n","        out = torch.cat([x1, x2, x3, x4], dim=1)\n","        return torch.relu(self.bn(out))\n","\n","class InceptionTime(nn.Module):\n","    def __init__(self, input_channels, num_classes):\n","        super().__init__()\n","        self.inception1 = InceptionModule(input_channels, 32)\n","        self.inception2 = InceptionModule(128, 64)\n","        self.gap = nn.AdaptiveAvgPool1d(1)\n","        self.fc = nn.Linear(256, num_classes)\n","\n","    def forward(self, x):\n","        x = x.transpose(1, 2).contiguous()\n","        x = self.inception1(x)\n","        x = self.inception2(x)\n","        x = self.gap(x).squeeze(-1)\n","        return self.fc(x)\n","\n","def count_model_bytes(model, input_shape, add_initial_transpose_write=False):\n","    bytes_per_elem = 4\n","    B, T, C = input_shape\n","\n","    input_read = B * T * C * bytes_per_elem\n","\n","    param_read = 0\n","    for p in model.parameters():\n","        param_read += p.numel() * bytes_per_elem\n","\n","    activation_read = 0\n","    activation_write = 0\n","\n","    with torch.no_grad():\n","        x = torch.randn(input_shape).to(device)\n","\n","        def hook_fn(m, inp, out):\n","            nonlocal activation_read, activation_write\n","            if isinstance(inp, tuple):\n","                inp = inp[0]\n","            activation_read += inp.numel() * bytes_per_elem\n","            activation_write += out.numel() * bytes_per_elem\n","\n","        hooks = []\n","        for m in model.modules():\n","            if len(list(m.children())) == 0 and not isinstance(m, (nn.MultiheadAttention,)):\n","                hooks.append(m.register_forward_hook(hook_fn))\n","\n","        output = model(x)\n","\n","        for h in hooks:\n","            h.remove()\n","\n","    output_write = output.numel() * bytes_per_elem\n","\n","    activation_write -= output_write\n","\n","    if add_initial_transpose_write:\n","        activation_write += B * C * T * bytes_per_elem\n","\n","    return {\n","        'input_read': input_read,\n","        'param_read': param_read,\n","        'activation_read': activation_read,\n","        'activation_write': activation_write,\n","        'output_write': output_write\n","    }\n","\n","def count_minirocket_bytes(model, input_shape):\n","    bytes_per_elem = 4\n","    B, T, C = input_shape\n","\n","    input_read = B * T * C * bytes_per_elem\n","\n","    kernels_read = model.num_kernels * C * 9 * bytes_per_elem\n","    fc_weight_read = model.fc.weight.numel() * bytes_per_elem\n","    fc_bias_read = model.fc.bias.numel() * bytes_per_elem if model.fc.bias is not None else 0\n","    param_read = kernels_read + fc_weight_read + fc_bias_read\n","\n","    transposed_write = B * C * T * bytes_per_elem\n","    conv_in_read = B * C * T * bytes_per_elem\n","    conv_out_write = B * model.num_kernels * T * bytes_per_elem\n","    conv_out_read_ppv = B * model.num_kernels * T * bytes_per_elem\n","    conv_out_read_mx = B * model.num_kernels * T * bytes_per_elem\n","    features_write = B * (model.num_kernels * 2) * bytes_per_elem\n","    features_read = B * (model.num_kernels * 2) * bytes_per_elem\n","\n","    activation_read = conv_in_read + conv_out_read_ppv + conv_out_read_mx + features_read\n","    activation_write = transposed_write + conv_out_write + features_write\n","\n","    output_write = B * model.fc.out_features * bytes_per_elem\n","\n","    return {\n","        'input_read': input_read,\n","        'param_read': param_read,\n","        'activation_read': activation_read,\n","        'activation_write': activation_write,\n","        'output_write': output_write\n","    }\n","\n","def count_multirocket_bytes(model, input_shape):\n","    bytes_per_elem = 4\n","    B, T, C = input_shape\n","\n","    input_read = B * T * C * bytes_per_elem\n","\n","    kernels_read = model.num_kernels * C * 9 * bytes_per_elem\n","    fc_weight_read = model.fc.weight.numel() * bytes_per_elem\n","    fc_bias_read = model.fc.bias.numel() * bytes_per_elem if model.fc.bias is not None else 0\n","    param_read = kernels_read + fc_weight_read + fc_bias_read\n","\n","    transposed_write = B * C * T * bytes_per_elem\n","\n","    conv_in_read = 0\n","    total_conv_out_write = 0\n","    total_conv_out_read = 0\n","    for d in [1, 2, 3]:\n","        K_d = int((model.dilations == d).sum().item())\n","        if K_d > 0:\n","            conv_in_read += B * C * T * bytes_per_elem\n","            total_conv_out_write += B * K_d * T * bytes_per_elem\n","            total_conv_out_read += 2 * B * K_d * T * bytes_per_elem\n","\n","    features_write = B * (model.num_kernels * 2) * bytes_per_elem\n","    features_read = B * (model.num_kernels * 2) * bytes_per_elem\n","\n","    activation_read = conv_in_read + total_conv_out_read + features_read\n","    activation_write = transposed_write + total_conv_out_write + features_write\n","\n","    output_write = B * model.fc.out_features * bytes_per_elem\n","\n","    return {\n","        'input_read': input_read,\n","        'param_read': param_read,\n","        'activation_read': activation_read,\n","        'activation_write': activation_write,\n","        'output_write': output_write\n","    }\n","\n","def count_tst_bytes(model, input_shape):\n","    BYTES = 4\n","    B, T, C = input_shape\n","\n","    d = model.embedding.out_features\n","    first = next(m for m in model.modules() if isinstance(m, nn.TransformerEncoderLayer))\n","    H = first.self_attn.num_heads\n","    ff_dim = first.linear1.out_features\n","    n_layers = len(model.transformer.layers)\n","\n","    input_read = B * T * C * BYTES\n","    param_read = sum(p.numel() for p in model.parameters()) * BYTES\n","\n","    act_read = 0\n","    act_write = 0\n","\n","    act_write += B * T * d * BYTES\n","\n","    for _ in range(n_layers):\n","        act_read += B * T * d * BYTES\n","        act_write += B * T * d * BYTES\n","\n","        act_write += 3 * B * T * d * BYTES\n","        act_read += 3 * B * T * d * BYTES\n","\n","        act_write += B * H * T * T * BYTES\n","        act_read += B * H * T * T * BYTES\n","\n","        act_write += B * T * d * BYTES\n","        act_read += B * T * d * BYTES\n","\n","        act_read += B * T * d * BYTES\n","        act_write += B * T * d * BYTES\n","\n","        act_read += B * T * d * BYTES\n","        act_write += B * T * ff_dim * BYTES\n","        act_read += B * T * ff_dim * BYTES\n","        act_write += B * T * d * BYTES\n","\n","    act_read += B * T * d * BYTES\n","    act_write += B * d * BYTES\n","\n","    act_read += B * d * BYTES\n","\n","    output_write = B * model.fc.out_features * BYTES\n","\n","    return {\n","        'input_read': input_read,\n","        'param_read': param_read,\n","        'activation_read': act_read,\n","        'activation_write': act_write,\n","        'output_write': output_write\n","    }\n","\n","test_x = np.load('data/test_x.npy')\n","batch_size = 1\n","test_batch = test_x[:batch_size]\n","\n","B, seq_len, n_channels = test_batch.shape\n","n_classes = 6\n","\n","models = {\n","    'TST': TransformerModel(n_channels, n_classes).to(device),\n","    'MiniROCKET': MiniROCKET(n_channels, n_classes).to(device),\n","    'MultiROCKET': MultiROCKET(n_channels, n_classes).to(device),\n","    'InceptionTime': InceptionTime(n_channels, n_classes).to(device)\n","}\n","\n","for name in models:\n","    models[name].load_state_dict(torch.load(f'models/{name.lower()}.pt', map_location=device))\n","    models[name].eval()\n","\n","results = []\n","\n","print(\"=\" * 70)\n","print(\"BYTES CALCULATION (Memory Read/Write per Inference)\")\n","print(\"=\" * 70)\n","\n","model_counters = {\n","    'TST': count_tst_bytes,\n","    'MiniROCKET': count_minirocket_bytes,\n","    'MultiROCKET': count_multirocket_bytes,\n","    'InceptionTime': lambda m, shp: count_model_bytes(m, shp, add_initial_transpose_write=True)\n","}\n","\n","for model_name, model in models.items():\n","    print(f\"\\n[{model_name}]\")\n","\n","    if model_name in model_counters:\n","        byte_counts = model_counters[model_name](model, test_batch.shape)\n","    else:\n","        byte_counts = count_model_bytes(model, test_batch.shape)\n","\n","    total_read = byte_counts['input_read'] + byte_counts['param_read'] + byte_counts['activation_read']\n","    total_write = byte_counts['activation_write'] + byte_counts['output_write']\n","    total_bytes = total_read + total_write\n","\n","    print(f\"  Input read:        {byte_counts['input_read']:>12,} bytes\")\n","    print(f\"  Param read:        {byte_counts['param_read']:>12,} bytes\")\n","    print(f\"  Activation read:   {byte_counts['activation_read']:>12,} bytes\")\n","    print(f\"  Activation write:  {byte_counts['activation_write']:>12,} bytes\")\n","    print(f\"  Output write:      {byte_counts['output_write']:>12,} bytes\")\n","    print(f\"  Total read:        {total_read:>12,} bytes\")\n","    print(f\"  Total write:       {total_write:>12,} bytes\")\n","    print(f\"  Total bytes:       {total_bytes:>12,} bytes\")\n","\n","    method = 'hook' if model_name == 'InceptionTime' else 'analytical'\n","\n","    results.append({\n","        'model': model_name,\n","        'input_read_bytes': byte_counts['input_read'],\n","        'param_read_bytes': byte_counts['param_read'],\n","        'activation_read_bytes': byte_counts['activation_read'],\n","        'activation_write_bytes': byte_counts['activation_write'],\n","        'output_write_bytes': byte_counts['output_write'],\n","        'total_read_bytes': total_read,\n","        'total_write_bytes': total_write,\n","        'total_bytes': total_bytes,\n","        'method': method\n","    })\n","\n","print(f\"\\n[KNN]\")\n","d = seq_len * n_channels\n","train_x = np.load('data/train_x.npy', mmap_mode='r')\n","n_train = len(train_x)\n","bytes_per_elem = 4\n","\n","input_read = d * bytes_per_elem\n","train_data_read = n_train * d * bytes_per_elem\n","distances_write = n_train * bytes_per_elem\n","k = 5\n","topk_read = n_train * bytes_per_elem\n","topk_write = k * (bytes_per_elem + 4)\n","output_write = n_classes * bytes_per_elem\n","\n","total_read = input_read + train_data_read + topk_read\n","total_write = distances_write + topk_write + output_write\n","total_bytes = total_read + total_write\n","\n","print(f\"  Input read:        {input_read:>12,} bytes\")\n","print(f\"  Param read:        {0:>12,} bytes\")\n","print(f\"  Activation read:   {train_data_read + topk_read:>12,} bytes\")\n","print(f\"  Activation write:  {distances_write + topk_write:>12,} bytes\")\n","print(f\"  Output write:      {output_write:>12,} bytes\")\n","print(f\"  Total read:        {total_read:>12,} bytes\")\n","print(f\"  Total write:       {total_write:>12,} bytes\")\n","print(f\"  Total bytes:       {total_bytes:>12,} bytes\")\n","\n","results.append({\n","    'model': 'KNN',\n","    'input_read_bytes': input_read,\n","    'param_read_bytes': 0,\n","    'activation_read_bytes': train_data_read + topk_read,\n","    'activation_write_bytes': distances_write + topk_write,\n","    'output_write_bytes': output_write,\n","    'total_read_bytes': total_read,\n","    'total_write_bytes': total_write,\n","    'total_bytes': total_bytes,\n","    'method': 'analytical'\n","})\n","\n","print(f\"\\n[RandomForest]\")\n","\n","with open('models/rf_cuml.pkl', 'rb') as f:\n","    rf_model = pickle.load(f)\n","\n","try:\n","    n_trees = getattr(rf_model, \"n_estimators\", getattr(rf_model, \"n_estimators_\", 100))\n","except:\n","    n_trees = 100\n","\n","avg_depth = 15\n","nodes_per_tree = 2 * avg_depth\n","bytes_per_node = 16\n","\n","input_read = d * bytes_per_elem\n","tree_nodes_read = n_trees * nodes_per_tree * bytes_per_node\n","path_write = n_trees * avg_depth * 4\n","votes_write = n_trees * bytes_per_elem\n","output_write = n_classes * bytes_per_elem\n","\n","total_read = input_read + tree_nodes_read\n","total_write = path_write + votes_write + output_write\n","total_bytes = total_read + total_write\n","\n","print(f\"  Input read:        {input_read:>12,} bytes\")\n","print(f\"  Param read:        {tree_nodes_read:>12,} bytes\")\n","print(f\"  Activation read:   {0:>12,} bytes\")\n","print(f\"  Activation write:  {path_write + votes_write:>12,} bytes\")\n","print(f\"  Output write:      {output_write:>12,} bytes\")\n","print(f\"  Total read:        {total_read:>12,} bytes\")\n","print(f\"  Total write:       {total_write:>12,} bytes\")\n","print(f\"  Total bytes:       {total_bytes:>12,} bytes\")\n","\n","results.append({\n","    'model': 'RandomForest',\n","    'input_read_bytes': input_read,\n","    'param_read_bytes': tree_nodes_read,\n","    'activation_read_bytes': 0,\n","    'activation_write_bytes': path_write + votes_write,\n","    'output_write_bytes': output_write,\n","    'total_read_bytes': total_read,\n","    'total_write_bytes': total_write,\n","    'total_bytes': total_bytes,\n","    'method': 'analytical'\n","})\n","\n","df = pd.DataFrame(results)\n","df.to_csv('logs/bytes_per_inf.csv', index=False)\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"BYTES SUMMARY (per inference)\")\n","print(\"=\" * 70)\n","print(f\"{'Model':<20} {'Total Read':<15} {'Total Write':<15} {'Total':<15}\")\n","print(\"-\" * 70)\n","for _, row in df.iterrows():\n","    print(f\"{row['model']:<20} {row['total_read_bytes']:>14,} {row['total_write_bytes']:>14,} {row['total_bytes']:>14,}\")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"CALCULATION METHODOLOGY\")\n","print(\"=\" * 70)\n","print(f\"\"\"\n","UNIT: Bytes (float32 = 4 bytes/element)\n","Batch size: {batch_size} (single inference)\n","\n","BREAKDOWN CATEGORIES:\n","  Input read:       Raw input tensor read once\n","  Param read:       Model weights/kernels read once\n","  Activation read:  Intermediate tensors read (for next layer/operation)\n","  Activation write: Intermediate tensors written\n","  Output write:     Final prediction written\n","\n","Deep Learning Models:\n","  TST:\n","    - Uses model's actual hyperparameters (d={models['TST'].embedding.out_features},\n","      H={next(m for m in models['TST'].modules() if isinstance(m, nn.TransformerEncoderLayer)).self_attn.num_heads},\n","      n_layers={len(models['TST'].transformer.layers)})\n","    - Params: embedding + 2×(MHA in_proj + out_proj + FFN) + final FC\n","    - Activations: Embedding output, LayerNorm (2 per layer), Q/K/V projections,\n","      attention scores, attention output, FFN intermediates, residual connections\n","    - Each tensor explicitly counted for read and write separately\n","\n","  MiniROCKET:\n","    - Params: {1000} conv kernels (9×{n_channels}) + FC weights\n","    - Activation flow:\n","      * Transpose writes (B×C×T×4)\n","      * Conv reads transposed input (B×C×T×4)\n","      * Conv writes output (B×K×T×4)\n","      * PPV and max each read conv output (2×B×K×T×4)\n","      * Features concatenated and read by FC (B×2K×4)\n","    - Functional ops (F.conv1d) explicitly counted\n","\n","  MultiROCKET:\n","    - Params: {2000} conv kernels + FC weights\n","    - Activation flow:\n","      * Each dilation group reads transposed input independently\n","      * 3 dilation groups × input read (B×C×T×4 each)\n","      * Per-group conv outputs and feature pooling\n","    - Functional ops explicitly counted\n","\n","  InceptionTime:\n","    - Params: All conv/BN/FC weights in Inception modules\n","    - Activations: Multi-branch conv outputs, pooling, GAP\n","    - Standard module hooks\n","\n","KNN (analytical):\n","  Input read:       {d} features × 4 bytes\n","  Activation read:  Training data ({n_train}×{d}×4 B) + distance array for top-k\n","  Activation write: {n_train} distances + top-{k} indices/distances\n","  Output write:     {n_classes} class probabilities\n","\n","  Note: Training data classified as activation (not parameter) since it's\n","        accessed during inference like intermediate computations\n","  Assumption: Brute-force all-pairs distance computation\n","  Alternative: Indexed search (KD-tree, Ball-tree) would reduce train data read\n","\n","RandomForest (analytical):\n","  Input read:       {d} features × 4 bytes\n","  Param read:       {n_trees} trees × {nodes_per_tree} nodes × {bytes_per_node} B/node\n","  Activation write: Path traces + per-tree votes\n","  Output write:     {n_classes} class probabilities\n","\n","  Node structure:   16 bytes (conservative: feature_idx + threshold + leaf_value + alignment)\n","                    Range: 12-16B depending on implementation (sklearn/cuML/Treelite)\n","  Assumption:       avg_depth ≈ {avg_depth}, nodes_per_tree ≈ 2×avg_depth\n","  Note:             Actual implementation may have pointers/overhead\n","\n","ASSUMPTIONS:\n","  - Single inference (batch=1)\n","  - FP32 precision (4 bytes per element)\n","  - Each tensor read once and written once per use\n","  - No gradient computation (inference only)\n","  - No memory reuse/in-place operations explicitly counted\n","  - ROCKET models: transpose creates new tensor (contiguous copy)\n","  - TST: Includes LayerNorm overhead (2 per transformer layer)\n","\"\"\")\n","\n","print(\"=\" * 70)\n","print(\"✓ Bytes statistics saved to logs/bytes_per_inf.csv\")\n","print(\"✓ Separate columns: input_read, param_read, activation_read/write, output_write\")\n","print(\"=\" * 70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lL_8b73_ESHt","executionInfo":{"status":"ok","timestamp":1762163559547,"user_tz":0,"elapsed":147,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"d89863c4-a9c1-45fb-d5e2-d79569d62200"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","BYTES CALCULATION (Memory Read/Write per Inference)\n","======================================================================\n","\n","[TST]\n","  Input read:               4,608 bytes\n","  Param read:             403,992 bytes\n","  Activation read:      1,278,208 bytes\n","  Activation write:     1,278,208 bytes\n","  Output write:                24 bytes\n","  Total read:           1,686,808 bytes\n","  Total write:          1,278,232 bytes\n","  Total bytes:          2,965,040 bytes\n","\n","[MiniROCKET]\n","  Input read:               4,608 bytes\n","  Param read:             372,024 bytes\n","  Activation read:      1,036,608 bytes\n","  Activation write:       524,608 bytes\n","  Output write:                24 bytes\n","  Total read:           1,413,240 bytes\n","  Total write:            524,632 bytes\n","  Total bytes:          1,937,872 bytes\n","\n","[MultiROCKET]\n","  Input read:               4,608 bytes\n","  Param read:             744,024 bytes\n","  Activation read:      2,077,824 bytes\n","  Activation write:     1,044,608 bytes\n","  Output write:                24 bytes\n","  Total read:           2,826,456 bytes\n","  Total write:          1,044,632 bytes\n","  Total bytes:          3,871,088 bytes\n","\n","[InceptionTime]\n","  Input read:               4,608 bytes\n","  Param read:             349,976 bytes\n","  Activation read:        679,424 bytes\n","  Activation write:       468,992 bytes\n","  Output write:                24 bytes\n","  Total read:           1,034,008 bytes\n","  Total write:            469,016 bytes\n","  Total bytes:          1,503,024 bytes\n","\n","[KNN]\n","  Input read:               4,608 bytes\n","  Param read:                   0 bytes\n","  Activation read:     25,601,212 bytes\n","  Activation write:        22,244 bytes\n","  Output write:                24 bytes\n","  Total read:          25,605,820 bytes\n","  Total write:             22,268 bytes\n","  Total bytes:         25,628,088 bytes\n","\n","[RandomForest]\n","  Input read:               4,608 bytes\n","  Param read:              48,000 bytes\n","  Activation read:              0 bytes\n","  Activation write:         6,400 bytes\n","  Output write:                24 bytes\n","  Total read:              52,608 bytes\n","  Total write:              6,424 bytes\n","  Total bytes:             59,032 bytes\n","\n","======================================================================\n","BYTES SUMMARY (per inference)\n","======================================================================\n","Model                Total Read      Total Write     Total          \n","----------------------------------------------------------------------\n","TST                       1,686,808      1,278,232      2,965,040\n","MiniROCKET                1,413,240        524,632      1,937,872\n","MultiROCKET               2,826,456      1,044,632      3,871,088\n","InceptionTime             1,034,008        469,016      1,503,024\n","KNN                      25,605,820         22,268     25,628,088\n","RandomForest                 52,608          6,424         59,032\n","\n","======================================================================\n","CALCULATION METHODOLOGY\n","======================================================================\n","\n","UNIT: Bytes (float32 = 4 bytes/element)\n","Batch size: 1 (single inference)\n","\n","BREAKDOWN CATEGORIES:\n","  Input read:       Raw input tensor read once\n","  Param read:       Model weights/kernels read once\n","  Activation read:  Intermediate tensors read (for next layer/operation)\n","  Activation write: Intermediate tensors written\n","  Output write:     Final prediction written\n","\n","Deep Learning Models:\n","  TST:\n","    - Uses model's actual hyperparameters (d=64,\n","      H=4,\n","      n_layers=2)\n","    - Params: embedding + 2×(MHA in_proj + out_proj + FFN) + final FC\n","    - Activations: Embedding output, LayerNorm (2 per layer), Q/K/V projections,\n","      attention scores, attention output, FFN intermediates, residual connections\n","    - Each tensor explicitly counted for read and write separately\n","\n","  MiniROCKET:\n","    - Params: 1000 conv kernels (9×9) + FC weights\n","    - Activation flow:\n","      * Transpose writes (B×C×T×4)\n","      * Conv reads transposed input (B×C×T×4)\n","      * Conv writes output (B×K×T×4)\n","      * PPV and max each read conv output (2×B×K×T×4)\n","      * Features concatenated and read by FC (B×2K×4)\n","    - Functional ops (F.conv1d) explicitly counted\n","\n","  MultiROCKET:\n","    - Params: 2000 conv kernels + FC weights\n","    - Activation flow:\n","      * Each dilation group reads transposed input independently\n","      * 3 dilation groups × input read (B×C×T×4 each)\n","      * Per-group conv outputs and feature pooling\n","    - Functional ops explicitly counted\n","\n","  InceptionTime:\n","    - Params: All conv/BN/FC weights in Inception modules\n","    - Activations: Multi-branch conv outputs, pooling, GAP\n","    - Standard module hooks\n","\n","KNN (analytical):\n","  Input read:       1152 features × 4 bytes\n","  Activation read:  Training data (5551×1152×4 B) + distance array for top-k\n","  Activation write: 5551 distances + top-5 indices/distances\n","  Output write:     6 class probabilities\n","\n","  Note: Training data classified as activation (not parameter) since it's\n","        accessed during inference like intermediate computations\n","  Assumption: Brute-force all-pairs distance computation\n","  Alternative: Indexed search (KD-tree, Ball-tree) would reduce train data read\n","\n","RandomForest (analytical):\n","  Input read:       1152 features × 4 bytes\n","  Param read:       100 trees × 30 nodes × 16 B/node\n","  Activation write: Path traces + per-tree votes\n","  Output write:     6 class probabilities\n","\n","  Node structure:   16 bytes (conservative: feature_idx + threshold + leaf_value + alignment)\n","                    Range: 12-16B depending on implementation (sklearn/cuML/Treelite)\n","  Assumption:       avg_depth ≈ 15, nodes_per_tree ≈ 2×avg_depth\n","  Note:             Actual implementation may have pointers/overhead\n","\n","ASSUMPTIONS:\n","  - Single inference (batch=1)\n","  - FP32 precision (4 bytes per element)\n","  - Each tensor read once and written once per use\n","  - No gradient computation (inference only)\n","  - No memory reuse/in-place operations explicitly counted\n","  - ROCKET models: transpose creates new tensor (contiguous copy)\n","  - TST: Includes LayerNorm overhead (2 per transformer layer)\n","\n","======================================================================\n","✓ Bytes statistics saved to logs/bytes_per_inf.csv\n","✓ Separate columns: input_read, param_read, activation_read/write, output_write\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["step 6"],"metadata":{"id":"KQbxOwNKqsHF"}},{"cell_type":"code","source":["import os\n","import time\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import pynvml\n","from scipy import stats\n","from abc import ABC, abstractmethod\n","import pickle\n","import cupy as cp\n","\n","os.makedirs('calibration', exist_ok=True)\n","\n","pynvml.nvmlInit()\n","handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n","\n","try:\n","    _ = pynvml.nvmlDeviceGetTotalEnergyConsumption(handle)\n","    energy_counter_supported = True\n","    method = \"energy_counter\"\n","except pynvml.NVMLError:\n","    energy_counter_supported = False\n","    method = \"power_sampling\"\n","\n","device = torch.device('cuda')\n","\n","def _sync_all():\n","    try:\n","        cp.cuda.runtime.deviceSynchronize()\n","    except Exception:\n","        pass\n","    torch.cuda.synchronize()\n","\n","class InferenceAdapter(ABC):\n","    def __init__(self, model_name):\n","        self.model_name = model_name\n","        self.model = None\n","        self.warmed_up = False\n","        self.expected_shape = None\n","\n","    def _validate(self, X, expect_channels=None, dtype=np.float32):\n","        X = np.asarray(X)\n","        if X.ndim != 3:\n","            raise ValueError(f\"Expected shape [B,T,C], got {X.shape}\")\n","        if self.expected_shape is not None and tuple(X.shape) != self.expected_shape:\n","            raise ValueError(f\"Shape mismatch: expected {self.expected_shape}, got {X.shape}\")\n","        if expect_channels is not None and X.shape[2] != expect_channels:\n","            raise ValueError(f\"Channel mismatch: expected {expect_channels}, got {X.shape[2]}\")\n","        if X.dtype != dtype:\n","            X = X.astype(dtype, copy=False)\n","        return X\n","\n","    @abstractmethod\n","    def load_model(self):\n","        pass\n","\n","    @abstractmethod\n","    def infer_one_batch(self, X):\n","        pass\n","\n","    def warmup(self, input_shape, n_warmup=20):\n","        self.expected_shape = tuple(input_shape)\n","        dummy_input = np.random.randn(*self.expected_shape).astype(np.float32)\n","        for _ in range(n_warmup):\n","            _ = self.infer_one_batch(dummy_input)\n","        self.warmed_up = True\n","\n","class KNNAdapter(InferenceAdapter):\n","    def __init__(self, n_channels=9):\n","        super().__init__(\"KNN\")\n","        self.n_channels = n_channels\n","        self.expected_flat = None\n","        self.load_model()\n","\n","    def load_model(self):\n","        with open('models/knn_cuml.pkl', 'rb') as f:\n","            self.model = pickle.load(f)\n","        self.expected_flat = getattr(self.model, \"n_features_in_\", None) or getattr(self.model, \"n_cols\", None)\n","\n","    def infer_one_batch(self, X):\n","        X = self._validate(X, self.n_channels)\n","        B, T, C = X.shape\n","        if self.expected_flat is not None and T * C != self.expected_flat:\n","            raise ValueError(f\"Flattened features {T*C} != model expects {self.expected_flat}\")\n","        X_flat = X.reshape(B, -1)\n","        with cp.cuda.Device(0):\n","            X_cp = cp.asarray(X_flat)\n","            probs_cp = self.model.predict_proba(X_cp)\n","        cp.cuda.runtime.deviceSynchronize()\n","        probs = cp.asnumpy(probs_cp)\n","        return probs.astype(np.float32, copy=False)\n","\n","class RandomForestAdapter(InferenceAdapter):\n","    def __init__(self, n_channels=9):\n","        super().__init__(\"RandomForest\")\n","        self.n_channels = n_channels\n","        self.expected_flat = None\n","        self.load_model()\n","\n","    def load_model(self):\n","        with open('models/rf_cuml.pkl', 'rb') as f:\n","            self.model = pickle.load(f)\n","        self.expected_flat = getattr(self.model, \"n_features_in_\", None) or getattr(self.model, \"n_cols\", None)\n","\n","    def infer_one_batch(self, X):\n","        X = self._validate(X, self.n_channels)\n","        B, T, C = X.shape\n","        if self.expected_flat is not None and T * C != self.expected_flat:\n","            raise ValueError(f\"Flattened features {T*C} != model expects {self.expected_flat}\")\n","        X_flat = X.reshape(B, -1)\n","        with cp.cuda.Device(0):\n","            X_cp = cp.asarray(X_flat)\n","            probs_cp = self.model.predict_proba(X_cp)\n","        cp.cuda.runtime.deviceSynchronize()\n","        probs = cp.asnumpy(probs_cp)\n","        return probs.astype(np.float32, copy=False)\n","\n","class TransformerModel(nn.Module):\n","    def __init__(self, input_dim, num_classes, d_model=64, nhead=4, num_layers=2):\n","        super().__init__()\n","        self.embedding = nn.Linear(input_dim, d_model)\n","        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,\n","                                                     dim_feedforward=256, batch_first=True)\n","        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n","        self.fc = nn.Linear(d_model, num_classes)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        x = self.transformer(x)\n","        x = x.mean(dim=1)\n","        return self.fc(x)\n","\n","class TSTAdapter(InferenceAdapter):\n","    def __init__(self, n_channels=9, n_classes=6):\n","        super().__init__(\"TST\")\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.load_model()\n","\n","    def load_model(self):\n","        self.model = TransformerModel(self.n_channels, self.n_classes).to(device)\n","        self.model.load_state_dict(torch.load('models/tst.pt', map_location=device))\n","        self.model.eval()\n","\n","    def infer_one_batch(self, X):\n","        X = self._validate(X, self.n_channels)\n","        X_tensor = torch.FloatTensor(X).to(device)\n","        with torch.inference_mode():\n","            logits = self.model(X_tensor)\n","            probs = torch.softmax(logits, dim=1)\n","        torch.cuda.synchronize()\n","        return probs.detach().cpu().numpy().astype(np.float32, copy=False)\n","\n","class MiniROCKET(nn.Module):\n","    def __init__(self, input_channels, num_classes, num_kernels=1000):\n","        super().__init__()\n","        self.kernels = nn.Parameter(torch.randn(num_kernels, input_channels, 9))\n","        self.fc = nn.Linear(num_kernels * 2, num_classes)\n","\n","    def forward(self, x):\n","        x = x.transpose(1, 2).contiguous()\n","        conv_out = torch.nn.functional.conv1d(x, self.kernels, padding=4)\n","        ppv = (conv_out > 0).float().mean(dim=2)\n","        mx = conv_out.amax(dim=2)\n","        features = torch.cat([ppv, mx], dim=1)\n","        return self.fc(features)\n","\n","class MiniROCKETAdapter(InferenceAdapter):\n","    def __init__(self, n_channels=9, n_classes=6):\n","        super().__init__(\"MiniROCKET\")\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.load_model()\n","\n","    def load_model(self):\n","        self.model = MiniROCKET(self.n_channels, self.n_classes).to(device)\n","        self.model.load_state_dict(torch.load('models/minirocket.pt', map_location=device))\n","        self.model.eval()\n","\n","    def infer_one_batch(self, X):\n","        X = self._validate(X, self.n_channels)\n","        X_tensor = torch.FloatTensor(X).to(device)\n","        with torch.inference_mode():\n","            logits = self.model(X_tensor)\n","            probs = torch.softmax(logits, dim=1)\n","        torch.cuda.synchronize()\n","        return probs.detach().cpu().numpy().astype(np.float32, copy=False)\n","\n","class MultiROCKET(nn.Module):\n","    def __init__(self, input_channels, num_classes, num_kernels=2000):\n","        super().__init__()\n","        self.num_kernels = num_kernels\n","        self.kernels = nn.Parameter(torch.randn(num_kernels, input_channels, 9))\n","        dilations = torch.randint(1, 4, (num_kernels,))\n","        self.register_buffer('dilations', dilations)\n","        self.fc = nn.Linear(num_kernels * 2, num_classes)\n","\n","    def forward(self, x):\n","        x = x.transpose(1, 2).contiguous()\n","        features_list = []\n","        for d in [1, 2, 3]:\n","            mask = self.dilations == d\n","            if mask.any():\n","                kernels_d = self.kernels[mask]\n","                conv_out = torch.nn.functional.conv1d(x, kernels_d, padding=4*d, dilation=d)\n","                ppv = (conv_out > 0).float().mean(dim=2)\n","                mx = conv_out.amax(dim=2)\n","                features_list.append(torch.cat([ppv, mx], dim=1))\n","        features = torch.cat(features_list, dim=1)\n","        return self.fc(features)\n","\n","class MultiROCKETAdapter(InferenceAdapter):\n","    def __init__(self, n_channels=9, n_classes=6):\n","        super().__init__(\"MultiROCKET\")\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.load_model()\n","\n","    def load_model(self):\n","        self.model = MultiROCKET(self.n_channels, self.n_classes).to(device)\n","        self.model.load_state_dict(torch.load('models/multirocket.pt', map_location=device))\n","        self.model.eval()\n","\n","    def infer_one_batch(self, X):\n","        X = self._validate(X, self.n_channels)\n","        X_tensor = torch.FloatTensor(X).to(device)\n","        with torch.inference_mode():\n","            logits = self.model(X_tensor)\n","            probs = torch.softmax(logits, dim=1)\n","        torch.cuda.synchronize()\n","        return probs.detach().cpu().numpy().astype(np.float32, copy=False)\n","\n","class InceptionModule(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n","        self.conv3 = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1)\n","        self.conv5 = nn.Conv1d(in_channels, out_channels, kernel_size=5, padding=2)\n","        self.pool = nn.Sequential(nn.MaxPool1d(3, stride=1, padding=1),\n","                                  nn.Conv1d(in_channels, out_channels, kernel_size=1))\n","        self.bn = nn.BatchNorm1d(out_channels * 4)\n","\n","    def forward(self, x):\n","        x1 = self.conv1(x)\n","        x2 = self.conv3(x)\n","        x3 = self.conv5(x)\n","        x4 = self.pool(x)\n","        out = torch.cat([x1, x2, x3, x4], dim=1)\n","        return torch.relu(self.bn(out))\n","\n","class InceptionTime(nn.Module):\n","    def __init__(self, input_channels, num_classes):\n","        super().__init__()\n","        self.inception1 = InceptionModule(input_channels, 32)\n","        self.inception2 = InceptionModule(128, 64)\n","        self.gap = nn.AdaptiveAvgPool1d(1)\n","        self.fc = nn.Linear(256, num_classes)\n","\n","    def forward(self, x):\n","        x = x.transpose(1, 2).contiguous()\n","        x = self.inception1(x)\n","        x = self.inception2(x)\n","        x = self.gap(x).squeeze(-1)\n","        return self.fc(x)\n","\n","class InceptionTimeAdapter(InferenceAdapter):\n","    def __init__(self, n_channels=9, n_classes=6):\n","        super().__init__(\"InceptionTime\")\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.load_model()\n","\n","    def load_model(self):\n","        self.model = InceptionTime(self.n_channels, self.n_classes).to(device)\n","        self.model.load_state_dict(torch.load('models/inceptiontime.pt', map_location=device))\n","        self.model.eval()\n","\n","    def infer_one_batch(self, X):\n","        X = self._validate(X, self.n_channels)\n","        X_tensor = torch.FloatTensor(X).to(device)\n","        with torch.inference_mode():\n","            logits = self.model(X_tensor)\n","            probs = torch.softmax(logits, dim=1)\n","        torch.cuda.synchronize()\n","        return probs.detach().cpu().numpy().astype(np.float32, copy=False)\n","\n","def measure_baseline(duration_sec=10, sample_interval_ms=100):\n","    samples = []\n","    start = time.time()\n","    interval_sec = sample_interval_ms / 1000.0\n","\n","    if energy_counter_supported:\n","        e0 = pynvml.nvmlDeviceGetTotalEnergyConsumption(handle)\n","        while time.time() - start < duration_sec:\n","            time.sleep(interval_sec)\n","            e1 = pynvml.nvmlDeviceGetTotalEnergyConsumption(handle)\n","            samples.append(e1 - e0)\n","            e0 = e1\n","    else:\n","        while time.time() - start < duration_sec:\n","            time.sleep(interval_sec)\n","            power = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0\n","            samples.append(power * interval_sec * 1000)\n","\n","    elapsed = time.time() - start\n","    total_mj = sum(samples)\n","    baseline_mj_per_sec = total_mj / elapsed\n","    return baseline_mj_per_sec\n","\n","def measure_energy_counter(adapter, X_batch, n_inferences):\n","    _sync_all()\n","    t0 = time.perf_counter()\n","    e_start = pynvml.nvmlDeviceGetTotalEnergyConsumption(handle)\n","\n","    for _ in range(n_inferences):\n","        _ = adapter.infer_one_batch(X_batch)\n","\n","    _sync_all()\n","    e_end = pynvml.nvmlDeviceGetTotalEnergyConsumption(handle)\n","    t1 = time.perf_counter()\n","\n","    energy_mj = e_end - e_start\n","    latency_ms = (t1 - t0) * 1000.0 / n_inferences\n","\n","    return energy_mj, latency_ms\n","\n","def measure_power_sampling(adapter, X_batch, n_inferences, sample_interval_ms=10):\n","    power_samples = []\n","    timestamps = []\n","\n","    def sample_power():\n","        while getattr(sample_power, 'running', True):\n","            t = time.perf_counter()\n","            p = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0\n","            power_samples.append(p)\n","            timestamps.append(t)\n","            time.sleep(sample_interval_ms / 1000.0)\n","\n","    import threading\n","    sample_power.running = True\n","    sampler_thread = threading.Thread(target=sample_power, daemon=True)\n","    sampler_thread.start()\n","\n","    _sync_all()\n","    t_start = time.perf_counter()\n","\n","    for _ in range(n_inferences):\n","        _ = adapter.infer_one_batch(X_batch)\n","\n","    _sync_all()\n","    t_end = time.perf_counter()\n","\n","    sample_power.running = False\n","    sampler_thread.join(timeout=1)\n","\n","    if len(power_samples) < 2 or len(timestamps) < 2:\n","        energy_mj = 0\n","    else:\n","        timestamps = np.array(timestamps)\n","        power_samples = np.array(power_samples)\n","        mask = (timestamps >= t_start) & (timestamps <= t_end)\n","        if mask.sum() >= 2:\n","            energy_j = np.trapz(power_samples[mask], timestamps[mask])\n","            energy_mj = energy_j * 1000\n","        else:\n","            energy_mj = np.mean(power_samples) * (t_end - t_start) * 1000\n","\n","    latency_ms = (t_end - t_start) * 1000.0 / n_inferences\n","\n","    return energy_mj, latency_ms\n","\n","test_x = np.load('data/test_x.npy')\n","batch_size = 1\n","test_batch = test_x[:batch_size]\n","\n","adapters = {\n","    'KNN': KNNAdapter(),\n","    'RandomForest': RandomForestAdapter(),\n","    'TST': TSTAdapter(),\n","    'MiniROCKET': MiniROCKETAdapter(),\n","    'MultiROCKET': MultiROCKETAdapter(),\n","    'InceptionTime': InceptionTimeAdapter()\n","}\n","\n","n_warmup = 20\n","n_rounds = 5\n","target_duration_sec = 10.0\n","\n","print(\"=\" * 70)\n","print(\"GPU ENERGY CALIBRATION\")\n","print(\"=\" * 70)\n","print(f\"Method: {method}\")\n","print(f\"Energy counter supported: {energy_counter_supported}\")\n","print(f\"Warmup: {n_warmup} inferences\")\n","print(f\"Target duration: {target_duration_sec:.1f}s/round\")\n","print(f\"Rounds: {n_rounds}\")\n","\n","results = []\n","\n","for name, adapter in adapters.items():\n","    print(f\"\\n[{name}]\")\n","\n","    print(\"  Warming up...\")\n","    adapter.warmup(test_batch.shape, n_warmup=n_warmup)\n","\n","    print(\"  Measuring baseline (pre)...\")\n","    baseline_pre_mj_per_sec = measure_baseline(duration_sec=5, sample_interval_ms=50)\n","    print(f\"  Baseline (pre): {baseline_pre_mj_per_sec:.2f} mJ/s\")\n","\n","    print(\"  Probing latency...\")\n","    if energy_counter_supported:\n","        _, probe_lat = measure_energy_counter(adapter, test_batch, 50)\n","    else:\n","        _, probe_lat = measure_power_sampling(adapter, test_batch, 50)\n","\n","    n_inferences_per_run = max(200, int(np.ceil(target_duration_sec / (probe_lat / 1000.0))))\n","    n_inferences_per_run = min(n_inferences_per_run, 1000)\n","\n","    print(f\"  Latency: {probe_lat:.3f} ms/inf → using {n_inferences_per_run} inferences × {n_rounds} rounds\")\n","\n","    round_E_total_mj = []\n","    round_duration_s = []\n","    round_latencies_ms = []\n","\n","    for r in range(n_rounds):\n","        if energy_counter_supported:\n","            energy_total_mj, latency_ms = measure_energy_counter(adapter, test_batch, n_inferences_per_run)\n","        else:\n","            energy_total_mj, latency_ms = measure_power_sampling(adapter, test_batch, n_inferences_per_run)\n","\n","        duration_sec = (latency_ms / 1000.0) * n_inferences_per_run\n","        round_E_total_mj.append(energy_total_mj)\n","        round_duration_s.append(duration_sec)\n","        round_latencies_ms.append(latency_ms)\n","\n","        print(f\"    Round {r+1}: Total={energy_total_mj:.2f} mJ, Lat={latency_ms:.3f} ms/inf\")\n","        time.sleep(0.5)\n","\n","    print(\"  Measuring baseline (post)...\")\n","    baseline_post_mj_per_sec = measure_baseline(duration_sec=5, sample_interval_ms=50)\n","    baseline_mj_per_sec = 0.5 * (baseline_pre_mj_per_sec + baseline_post_mj_per_sec)\n","    print(f\"  Baseline (post): {baseline_post_mj_per_sec:.2f} mJ/s → Used={baseline_mj_per_sec:.2f} mJ/s\")\n","\n","    round_E_total_mj = np.array(round_E_total_mj)\n","    round_duration_s = np.array(round_duration_s)\n","    round_latencies_ms = np.array(round_latencies_ms)\n","\n","    energy_total_per_inf = round_E_total_mj / n_inferences_per_run\n","    energy_net_per_inf = (round_E_total_mj - baseline_mj_per_sec * round_duration_s) / n_inferences_per_run\n","\n","    mean_energy_total = energy_total_per_inf.mean()\n","    std_energy_total = energy_total_per_inf.std(ddof=1)\n","    sem_energy_total = std_energy_total / np.sqrt(n_rounds)\n","    ci95_energy_total = sem_energy_total * stats.t.ppf(0.975, n_rounds - 1)\n","\n","    mean_energy_net = energy_net_per_inf.mean()\n","    std_energy_net = energy_net_per_inf.std(ddof=1)\n","    sem_energy_net = std_energy_net / np.sqrt(n_rounds)\n","    ci95_energy_net = sem_energy_net * stats.t.ppf(0.975, n_rounds - 1)\n","\n","    mean_latency = round_latencies_ms.mean()\n","    std_latency = round_latencies_ms.std(ddof=1)\n","    sem_latency = std_latency / np.sqrt(n_rounds)\n","    ci95_latency = sem_latency * stats.t.ppf(0.975, n_rounds - 1)\n","\n","    results.append({\n","        'model': name,\n","        'mean_energy_total_mj_per_inf': mean_energy_total,\n","        'std_energy_total_mj_per_inf': std_energy_total,\n","        'ci95_energy_total_mj_per_inf': ci95_energy_total,\n","        'mean_energy_net_mj_per_inf': mean_energy_net,\n","        'std_energy_net_mj_per_inf': std_energy_net,\n","        'ci95_energy_net_mj_per_inf': ci95_energy_net,\n","        'mean_latency_ms_per_inf': mean_latency,\n","        'std_latency_ms_per_inf': std_latency,\n","        'ci95_latency_ms_per_inf': ci95_latency,\n","        'method': method,\n","        'baseline_subtracted_per_round': True,\n","        'n_rounds': n_rounds,\n","        'n_inferences_per_round': n_inferences_per_run,\n","        'baseline_mj_per_sec': baseline_mj_per_sec,\n","        'baseline_pre_mj_per_sec': baseline_pre_mj_per_sec,\n","        'baseline_post_mj_per_sec': baseline_post_mj_per_sec\n","    })\n","\n","df = pd.DataFrame(results)\n","df.to_csv('calibration/calibration_measurements.csv', index=False)\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"CALIBRATION SUMMARY\")\n","print(\"=\" * 70)\n","print(f\"{'Model':<20} {'E_net (mJ/inf)':<25} {'E_total (mJ/inf)':<25} {'Latency (ms/inf)':<25}\")\n","print(f\"{'':20} {'Mean ± 95%CI':<25} {'Mean ± 95%CI':<25} {'Mean ± 95%CI':<25}\")\n","print(\"-\" * 70)\n","for _, row in df.iterrows():\n","    net_str = f\"{row['mean_energy_net_mj_per_inf']:.3f} ± {row['ci95_energy_net_mj_per_inf']:.3f}\"\n","    total_str = f\"{row['mean_energy_total_mj_per_inf']:.3f} ± {row['ci95_energy_total_mj_per_inf']:.3f}\"\n","    latency_str = f\"{row['mean_latency_ms_per_inf']:.3f} ± {row['ci95_latency_ms_per_inf']:.3f}\"\n","    print(f\"{row['model']:<20} {net_str:<25} {total_str:<25} {latency_str:<25}\")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"MEASUREMENT DETAILS\")\n","print(\"=\" * 70)\n","print(f\"Method: {method}\")\n","print(\"  - Wall-clock + full device synchronization (CuPy + PyTorch)\")\n","if method == \"energy_counter\":\n","    print(\"  - Energy counter read at start/end\")\n","else:\n","    print(\"  - Power sampling with trapz integration\")\n","print(f\"Baseline: Sandwich method (pre + post, per-model)\")\n","print(f\"Adaptive inferences: 200-1000 per round\")\n","print(f\"Target duration: {target_duration_sec:.1f}s/round (all models)\")\n","print(f\"Rounds: {n_rounds} (all models, 0.5s rest between rounds)\")\n","print(f\"Confidence interval: 95%\")\n","print(f\"Units: mJ per inference, ms per inference\")\n","print(\"\\nE_net = (E_total - baseline × duration) / n_inferences\")\n","print(\"E_total = raw energy consumption without baseline subtraction\")\n","print(\"\\n\" + \"=\" * 70)\n","print(\"✓ Calibration measurements saved to calibration/calibration_measurements.csv\")\n","print(\"=\" * 70)\n","\n","pynvml.nvmlShutdown()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vnyi889_ETiN","executionInfo":{"status":"ok","timestamp":1762172887531,"user_tz":0,"elapsed":165106,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"b5996ff0-08c3-42df-e1ea-8f3ab2bc7c92"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","GPU ENERGY CALIBRATION\n","======================================================================\n","Method: energy_counter\n","Energy counter supported: True\n","Warmup: 20 inferences\n","Target duration: 10.0s/round\n","Rounds: 5\n","\n","[KNN]\n","  Warming up...\n","  Measuring baseline (pre)...\n","  Baseline (pre): 31602.84 mJ/s\n","  Probing latency...\n","  Latency: 3.149 ms/inf → using 1000 inferences × 5 rounds\n","    Round 1: Total=104885.00 mJ, Lat=3.105 ms/inf\n","    Round 2: Total=104841.00 mJ, Lat=3.033 ms/inf\n","    Round 3: Total=101600.00 mJ, Lat=3.028 ms/inf\n","    Round 4: Total=105004.00 mJ, Lat=3.068 ms/inf\n","    Round 5: Total=101995.00 mJ, Lat=2.997 ms/inf\n","  Measuring baseline (post)...\n","  Baseline (post): 30948.47 mJ/s → Used=31275.66 mJ/s\n","\n","[RandomForest]\n","  Warming up...\n","  Measuring baseline (pre)...\n","  Baseline (pre): 30938.82 mJ/s\n","  Probing latency...\n","  Latency: 18.822 ms/inf → using 532 inferences × 5 rounds\n","    Round 1: Total=308013.00 mJ, Lat=18.564 ms/inf\n","    Round 2: Total=307735.00 mJ, Lat=18.629 ms/inf\n","    Round 3: Total=308752.00 mJ, Lat=18.530 ms/inf\n","    Round 4: Total=306014.00 mJ, Lat=18.475 ms/inf\n","    Round 5: Total=306011.00 mJ, Lat=18.419 ms/inf\n","  Measuring baseline (post)...\n","  Baseline (post): 31018.84 mJ/s → Used=30978.83 mJ/s\n","\n","[TST]\n","  Warming up...\n","  Measuring baseline (pre)...\n","  Baseline (pre): 31022.75 mJ/s\n","  Probing latency...\n","  Latency: 1.776 ms/inf → using 1000 inferences × 5 rounds\n","    Round 1: Total=57831.00 mJ, Lat=1.689 ms/inf\n","    Round 2: Total=57596.00 mJ, Lat=1.729 ms/inf\n","    Round 3: Total=57582.00 mJ, Lat=1.696 ms/inf\n","    Round 4: Total=57555.00 mJ, Lat=1.698 ms/inf\n","    Round 5: Total=57549.00 mJ, Lat=1.689 ms/inf\n","  Measuring baseline (post)...\n","  Baseline (post): 30980.69 mJ/s → Used=31001.72 mJ/s\n","\n","[MiniROCKET]\n","  Warming up...\n","  Measuring baseline (pre)...\n","  Baseline (pre): 30983.92 mJ/s\n","  Probing latency...\n","  Latency: 0.560 ms/inf → using 1000 inferences × 5 rounds\n","    Round 1: Total=16951.00 mJ, Lat=0.499 ms/inf\n","    Round 2: Total=16902.00 mJ, Lat=0.478 ms/inf\n","    Round 3: Total=16945.00 mJ, Lat=0.487 ms/inf\n","    Round 4: Total=13586.00 mJ, Lat=0.477 ms/inf\n","    Round 5: Total=13627.00 mJ, Lat=0.495 ms/inf\n","  Measuring baseline (post)...\n","  Baseline (post): 31572.43 mJ/s → Used=31278.18 mJ/s\n","\n","[MultiROCKET]\n","  Warming up...\n","  Measuring baseline (pre)...\n","  Baseline (pre): 30945.38 mJ/s\n","  Probing latency...\n","  Latency: 1.405 ms/inf → using 1000 inferences × 5 rounds\n","    Round 1: Total=44255.00 mJ, Lat=1.294 ms/inf\n","    Round 2: Total=44092.00 mJ, Lat=1.285 ms/inf\n","    Round 3: Total=40766.00 mJ, Lat=1.246 ms/inf\n","    Round 4: Total=43992.00 mJ, Lat=1.252 ms/inf\n","    Round 5: Total=40700.00 mJ, Lat=1.264 ms/inf\n","  Measuring baseline (post)...\n","  Baseline (post): 31480.81 mJ/s → Used=31213.09 mJ/s\n","\n","[InceptionTime]\n","  Warming up...\n","  Measuring baseline (pre)...\n","  Baseline (pre): 30844.42 mJ/s\n","  Probing latency...\n","  Latency: 1.295 ms/inf → using 1000 inferences × 5 rounds\n","    Round 1: Total=40172.00 mJ, Lat=1.182 ms/inf\n","    Round 2: Total=40075.00 mJ, Lat=1.190 ms/inf\n","    Round 3: Total=40110.00 mJ, Lat=1.223 ms/inf\n","    Round 4: Total=40096.00 mJ, Lat=1.221 ms/inf\n","    Round 5: Total=40046.00 mJ, Lat=1.203 ms/inf\n","  Measuring baseline (post)...\n","  Baseline (post): 30943.85 mJ/s → Used=30894.14 mJ/s\n","\n","======================================================================\n","CALIBRATION SUMMARY\n","======================================================================\n","Model                E_net (mJ/inf)            E_total (mJ/inf)          Latency (ms/inf)         \n","                     Mean ± 95%CI              Mean ± 95%CI              Mean ± 95%CI             \n","----------------------------------------------------------------------\n","KNN                  8.389 ± 1.463             103.665 ± 2.125           3.046 ± 0.051            \n","RandomForest         3.805 ± 2.323             577.641 ± 2.887           18.523 ± 0.100           \n","TST                  4.921 ± 0.689             57.623 ± 0.147            1.700 ± 0.021            \n","MiniROCKET           0.361 ± 2.247             15.602 ± 2.262            0.487 ± 0.012            \n","MultiROCKET          3.178 ± 1.920             42.761 ± 2.302            1.268 ± 0.026            \n","InceptionTime        2.907 ± 0.725             40.100 ± 0.058            1.204 ± 0.023            \n","\n","======================================================================\n","MEASUREMENT DETAILS\n","======================================================================\n","Method: energy_counter\n","  - Wall-clock + full device synchronization (CuPy + PyTorch)\n","  - Energy counter read at start/end\n","Baseline: Sandwich method (pre + post, per-model)\n","Adaptive inferences: 200-1000 per round\n","Target duration: 10.0s/round (all models)\n","Rounds: 5 (all models, 0.5s rest between rounds)\n","Confidence interval: 95%\n","Units: mJ per inference, ms per inference\n","\n","E_net = (E_total - baseline × duration) / n_inferences\n","E_total = raw energy consumption without baseline subtraction\n","\n","======================================================================\n","✓ Calibration measurements saved to calibration/calibration_measurements.csv\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["step 7"],"metadata":{"id":"La3-HEE4FT0B"}},{"cell_type":"code","source":["import os\n","import json\n","import numpy as np\n","import pandas as pd\n","\n","os.makedirs('logs', exist_ok=True)\n","\n","macs_df = pd.read_csv('logs/macs_per_inf.csv')\n","bytes_df = pd.read_csv('logs/bytes_per_inf.csv')\n","energy_df = pd.read_csv('calibration/calibration_measurements.csv')\n","\n","macs_dict = dict(zip(macs_df['model'], macs_df['macs_per_inf']))\n","bytes_dict = dict(zip(bytes_df['model'], bytes_df['total_bytes']))\n","energy_dict = dict(zip(energy_df['model'], energy_df['mean_energy_net_mj_per_inf']))\n","energy_ci_dict = dict(zip(energy_df['model'], energy_df['ci95_energy_net_mj_per_inf']))\n","latency_dict = dict(zip(energy_df['model'], energy_df['mean_latency_ms_per_inf']))\n","latency_ci_dict = dict(zip(energy_df['model'], energy_df['ci95_latency_ms_per_inf']))\n","\n","all_models = set(macs_dict.keys()) & set(bytes_dict.keys()) & set(energy_dict.keys())\n","\n","full_data = []\n","for model in all_models:\n","    flops = macs_dict[model] * 2\n","    bytes_total = bytes_dict[model]\n","    energy = energy_dict[model]\n","    energy_ci = energy_ci_dict[model]\n","    latency = latency_dict[model]\n","    latency_ci = latency_ci_dict[model]\n","\n","    full_data.append({\n","        'model': model,\n","        'flops_per_inf': flops,\n","        'bytes_per_inf': bytes_total,\n","        'energy_mj_per_inf': energy,\n","        'energy_ci95_mj_per_inf': energy_ci,\n","        'latency_ms_per_inf': latency,\n","        'latency_ci95_ms_per_inf': latency_ci,\n","        'flops_bytes_ratio': flops / bytes_total if bytes_total > 0 else 0\n","    })\n","\n","full_df = pd.DataFrame(full_data)\n","full_df = full_df.sort_values('flops_bytes_ratio')\n","\n","calibration_df = full_df.copy()\n","\n","print(\"=\" * 70)\n","print(\"CALIBRATION SAMPLE SELECTION\")\n","print(\"=\" * 70)\n","print(f\"\\nTotal models: {len(full_df)}\")\n","print(f\"Calibration set: {len(calibration_df)} models (all models used)\")\n","print(\"\\nModels (sorted by FLOPs/Bytes ratio):\")\n","print(\"-\" * 70)\n","print(f\"{'Model':<20} {'FLOPs':<15} {'Bytes':<15} {'Ratio':<12} {'Energy (mJ)':<15}\")\n","print(\"-\" * 70)\n","for _, row in full_df.iterrows():\n","    print(f\"{row['model']:<20} {row['flops_per_inf']:>14,.0f} {row['bytes_per_inf']:>14,.0f} \"\n","          f\"{row['flops_bytes_ratio']:>11.2f} {row['energy_mj_per_inf']:>14.3f}\")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"ALL MODELS DETAILS\")\n","print(\"=\" * 70)\n","for _, row in calibration_df.iterrows():\n","    print(f\"\\n[{row['model']}]\")\n","    print(f\"  FLOPs:           {row['flops_per_inf']:>14,.0f}\")\n","    print(f\"  Bytes:           {row['bytes_per_inf']:>14,.0f}\")\n","    print(f\"  FLOPs/Bytes:     {row['flops_bytes_ratio']:>14.2f}\")\n","    print(f\"  Energy:          {row['energy_mj_per_inf']:>14.3f} ± {row['energy_ci95_mj_per_inf']:.3f} mJ/inf\")\n","    print(f\"  Latency:         {row['latency_ms_per_inf']:>14.3f} ± {row['latency_ci95_ms_per_inf']:.3f} ms/inf\")\n","\n","ratio_range = calibration_df['flops_bytes_ratio'].max() / calibration_df['flops_bytes_ratio'].min()\n","flops_range = calibration_df['flops_per_inf'].max() / calibration_df['flops_per_inf'].min()\n","bytes_range = calibration_df['bytes_per_inf'].max() / calibration_df['bytes_per_inf'].min()\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"COVERAGE ANALYSIS\")\n","print(\"=\" * 70)\n","print(f\"FLOPs/Bytes ratio range:  {ratio_range:.2f}x  \"\n","      f\"({calibration_df['flops_bytes_ratio'].min():.2f} → {calibration_df['flops_bytes_ratio'].max():.2f})\")\n","print(f\"FLOPs range:              {flops_range:.2f}x  \"\n","      f\"({calibration_df['flops_per_inf'].min():,.0f} → {calibration_df['flops_per_inf'].max():,.0f})\")\n","print(f\"Bytes range:              {bytes_range:.2f}x  \"\n","      f\"({calibration_df['bytes_per_inf'].min():,.0f} → {calibration_df['bytes_per_inf'].max():,.0f})\")\n","\n","os.makedirs('calibration', exist_ok=True)\n","calibration_df.to_csv('logs/calibration_df.csv', index=False)\n","calibration_df.to_csv('calibration/calibration_df.csv', index=False)\n","\n","ratio_min = calibration_df['flops_bytes_ratio'].replace(0, np.nan).min()\n","ratio_max = calibration_df['flops_bytes_ratio'].max()\n","ratio_span = (ratio_max / ratio_min) if np.isfinite(ratio_min) and ratio_min > 0 else float('inf')\n","\n","q30 = full_df['flops_bytes_ratio'].quantile(0.30)\n","q70 = full_df['flops_bytes_ratio'].quantile(0.70)\n","covers_low = ratio_min <= q30\n","covers_high = ratio_max >= q70\n","\n","coverage_report = {\n","    \"timestamp_utc\": pd.Timestamp.utcnow().isoformat(),\n","    \"selected_models\": calibration_df['model'].tolist(),\n","    \"n_models\": len(calibration_df),\n","    \"coverage\": {\n","        \"ratio_min\": float(ratio_min),\n","        \"ratio_max\": float(ratio_max),\n","        \"ratio_span_x\": float(ratio_span),\n","        \"flops_min\": int(calibration_df['flops_per_inf'].min()),\n","        \"flops_max\": int(calibration_df['flops_per_inf'].max()),\n","        \"bytes_min\": int(calibration_df['bytes_per_inf'].min()),\n","        \"bytes_max\": int(calibration_df['bytes_per_inf'].max()),\n","        \"q30_threshold\": float(q30),\n","        \"q70_threshold\": float(q70),\n","        \"covers_bytes_dominant\": bool(covers_low),\n","        \"covers_flops_dominant\": bool(covers_high)\n","    },\n","    \"quality_gate\": {\n","        \"ratio_span_min\": 2.0,\n","        \"min_models\": 3,\n","        \"requires_low_coverage\": True,\n","        \"requires_high_coverage\": True\n","    },\n","    \"note\": \"All-six model calibration (KNN, RF, TST, MiniROCKET, MultiROCKET, InceptionTime)\"\n","}\n","\n","with open('calibration/coverage.json', 'w') as f:\n","    json.dump(coverage_report, f, indent=2)\n","\n","if ratio_span >= 2.0:\n","    print(\"\\n✓ Good coverage: FLOPs/Bytes ratio spans ≥2x (FLOPs-dominant to Bytes-dominant)\")\n","    if covers_low:\n","        print(f\"✓ Covers Bytes-dominant region (ratio_min={ratio_min:.2f} ≤ Q30={q30:.2f})\")\n","    if covers_high:\n","        print(f\"✓ Covers FLOPs-dominant region (ratio_max={ratio_max:.2f} ≥ Q70={q70:.2f})\")\n","else:\n","    print(\"\\n⚠ Warning: FLOPs/Bytes ratio range <2x\")\n","\n","assert (ratio_span >= 2.0 and covers_low and covers_high and len(calibration_df) >= 3), (\n","    f\"Step7 quality gate failed: ratio_span={ratio_span:.2f}x (need ≥2x), \"\n","    f\"covers_low={covers_low}, covers_high={covers_high}, n={len(calibration_df)} (need ≥3)\"\n",")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"✓ Calibration data saved to calibration/calibration_df.csv\")\n","print(\"✓ Backup copy saved to logs/calibration_df.csv\")\n","print(\"✓ Coverage report saved to calibration/coverage.json\")\n","print(f\"✓ Quality gate passed: {len(calibration_df)} models, {ratio_span:.2f}x span, both ends covered\")\n","print(\"=\" * 70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FPFYfYxgJOE2","executionInfo":{"status":"ok","timestamp":1762172887600,"user_tz":0,"elapsed":58,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"1f3bebc7-19f5-4f6a-dd1f-97ac139e3cbf"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","CALIBRATION SAMPLE SELECTION\n","======================================================================\n","\n","Total models: 6\n","Calibration set: 6 models (all models used)\n","\n","Models (sorted by FLOPs/Bytes ratio):\n","----------------------------------------------------------------------\n","Model                FLOPs           Bytes           Ratio        Energy (mJ)    \n","----------------------------------------------------------------------\n","RandomForest                  6,000         59,032        0.10          3.805\n","KNN                      25,579,008     25,628,088        1.00          8.389\n","MiniROCKET               20,760,000      1,937,872       10.71          0.361\n","MultiROCKET              41,520,000      3,871,088       10.73          3.178\n","TST                      34,030,336      2,965,040       11.48          4.921\n","InceptionTime            21,908,480      1,503,024       14.58          2.907\n","\n","======================================================================\n","ALL MODELS DETAILS\n","======================================================================\n","\n","[RandomForest]\n","  FLOPs:                    6,000\n","  Bytes:                   59,032\n","  FLOPs/Bytes:               0.10\n","  Energy:                   3.805 ± 2.323 mJ/inf\n","  Latency:                 18.523 ± 0.100 ms/inf\n","\n","[KNN]\n","  FLOPs:               25,579,008\n","  Bytes:               25,628,088\n","  FLOPs/Bytes:               1.00\n","  Energy:                   8.389 ± 1.463 mJ/inf\n","  Latency:                  3.046 ± 0.051 ms/inf\n","\n","[MiniROCKET]\n","  FLOPs:               20,760,000\n","  Bytes:                1,937,872\n","  FLOPs/Bytes:              10.71\n","  Energy:                   0.361 ± 2.247 mJ/inf\n","  Latency:                  0.487 ± 0.012 ms/inf\n","\n","[MultiROCKET]\n","  FLOPs:               41,520,000\n","  Bytes:                3,871,088\n","  FLOPs/Bytes:              10.73\n","  Energy:                   3.178 ± 1.920 mJ/inf\n","  Latency:                  1.268 ± 0.026 ms/inf\n","\n","[TST]\n","  FLOPs:               34,030,336\n","  Bytes:                2,965,040\n","  FLOPs/Bytes:              11.48\n","  Energy:                   4.921 ± 0.689 mJ/inf\n","  Latency:                  1.700 ± 0.021 ms/inf\n","\n","[InceptionTime]\n","  FLOPs:               21,908,480\n","  Bytes:                1,503,024\n","  FLOPs/Bytes:              14.58\n","  Energy:                   2.907 ± 0.725 mJ/inf\n","  Latency:                  1.204 ± 0.023 ms/inf\n","\n","======================================================================\n","COVERAGE ANALYSIS\n","======================================================================\n","FLOPs/Bytes ratio range:  143.41x  (0.10 → 14.58)\n","FLOPs range:              6920.00x  (6,000 → 41,520,000)\n","Bytes range:              434.14x  (59,032 → 25,628,088)\n","\n","✓ Good coverage: FLOPs/Bytes ratio spans ≥2x (FLOPs-dominant to Bytes-dominant)\n","✓ Covers Bytes-dominant region (ratio_min=0.10 ≤ Q30=5.86)\n","✓ Covers FLOPs-dominant region (ratio_max=14.58 ≥ Q70=11.10)\n","\n","======================================================================\n","✓ Calibration data saved to calibration/calibration_df.csv\n","✓ Backup copy saved to logs/calibration_df.csv\n","✓ Coverage report saved to calibration/coverage.json\n","✓ Quality gate passed: 6 models, 143.41x span, both ends covered\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["step 8"],"metadata":{"id":"z8zOexuUFWmX"}},{"cell_type":"code","source":["import os\n","import json\n","import numpy as np\n","import pandas as pd\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import r2_score, mean_squared_error\n","from scipy import stats\n","from scipy.optimize import lsq_linear\n","import matplotlib\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","\n","os.makedirs('logs', exist_ok=True)\n","\n","df = pd.read_csv('logs/calibration_df.csv')\n","\n","X = df[['flops_per_inf', 'bytes_per_inf']].values\n","y = df['energy_mj_per_inf'].values\n","\n","# 从 CI95 还原 SE（标准误），做方差平均\n","if 'n_rounds' in df.columns:\n","    R = df['n_rounds'].astype(int).values\n","else:\n","    R = np.full(len(df), 5, dtype=int)\n","\n","ci95 = df['energy_ci95_mj_per_inf'].values\n","tcrit = stats.t.ppf(0.975, np.clip(R - 1, 1, None))\n","y_meas_SE = ci95 / tcrit\n","pooled_meas_var = np.mean(y_meas_SE ** 2)\n","pooled_meas_SE = np.sqrt(pooled_meas_var)\n","\n","# 标准化\n","scaler_X = StandardScaler()\n","X_scaled = scaler_X.fit_transform(X)\n","\n","# 加权最小二乘（WLS），权重基于 SE\n","w = 1.0 / np.maximum(y_meas_SE**2, 1e-12)\n","model = LinearRegression()\n","model.fit(X_scaled, y, sample_weight=w)\n","\n","alpha_scaled, beta_scaled = model.coef_\n","gamma = model.intercept_\n","\n","flops_mean, bytes_mean = scaler_X.mean_\n","flops_std, bytes_std = scaler_X.scale_\n","\n","alpha = alpha_scaled / flops_std\n","beta = beta_scaled / bytes_std\n","gamma_unscaled = gamma - alpha * flops_mean - beta * bytes_mean\n","\n","# 残差计算\n","y_pred = model.predict(X_scaled)\n","residuals = y - y_pred\n","\n","n = len(df)\n","p = 3\n","\n","# 未加权版本（有量纲 mJ）\n","SSE = np.sum(residuals**2)\n","sigma_resid_unw = np.sqrt(SSE / (n - p))\n","r2_unw = r2_score(y, y_pred)\n","mse_unw = mean_squared_error(y, y_pred)\n","rmse_unw = np.sqrt(mse_unw)\n","\n","# 加权版本（用于WLS诊断）\n","SSE_w = np.sum(w * residuals**2)\n","sigma_resid_w = np.sqrt(SSE_w / max(n - p, 1))  # 无量纲（whitened）\n","rmse_w = np.sqrt(np.average(residuals**2, weights=w))\n","\n","# 加权R²\n","def r2_weighted(y_true, y_pred, weights):\n","    ybar = np.average(y_true, weights=weights)\n","    ss_res = np.sum(weights * (y_true - y_pred)**2)\n","    ss_tot = np.sum(weights * (y_true - ybar)**2)\n","    return 1.0 - ss_res / np.maximum(ss_tot, 1e-12)\n","\n","r2_w = r2_weighted(y, y_pred, w)\n","\n","# 模型不确定度（使用加权RMSE，与WLS口径一致，单位 mJ）\n","sigma_model = rmse_w\n","\n","# 总不确定度（方差相加，单位 mJ）\n","total_uncertainty = np.sqrt(sigma_model**2 + pooled_meas_var)\n","\n","# Δ95：默认用t分布（更保守），同时保存z版本\n","t_crit_overall = stats.t.ppf(0.975, n - p)\n","delta_95_t = t_crit_overall * total_uncertainty\n","delta_95_z = 1.96 * total_uncertainty\n","\n","# 非负约束 WLS\n","X_scaled_with_intercept = np.column_stack([X_scaled, np.ones(n)])\n","w_sqrt = np.sqrt(w)\n","X_weighted = X_scaled_with_intercept * w_sqrt[:, np.newaxis]\n","y_weighted = y * w_sqrt\n","\n","result_nnls = lsq_linear(X_weighted, y_weighted, bounds=(0, np.inf), method='bvls')\n","coef_nnls_scaled = result_nnls.x\n","\n","alpha_nnls_scaled, beta_nnls_scaled, gamma_nnls = coef_nnls_scaled\n","alpha_nnls = alpha_nnls_scaled / flops_std\n","beta_nnls = beta_nnls_scaled / bytes_std\n","gamma_nnls_unscaled = gamma_nnls - alpha_nnls * flops_mean - beta_nnls * bytes_mean\n","\n","y_pred_nnls = X_scaled_with_intercept @ coef_nnls_scaled\n","r2_nnls_w = r2_weighted(y, y_pred_nnls, w)\n","\n","results = []\n","for i, row in df.iterrows():\n","    e_point = y_pred[i]\n","    e_upper = e_point + delta_95_t\n","    e_point_nnls = y_pred_nnls[i]\n","    e_upper_nnls = e_point_nnls + delta_95_t\n","    results.append({\n","        'model': row['model'],\n","        'flops': row['flops_per_inf'],\n","        'bytes': row['bytes_per_inf'],\n","        'energy_measured_mj': row['energy_mj_per_inf'],\n","        'energy_predicted_mj': e_point,\n","        'energy_upper95_mj': e_upper,\n","        'energy_predicted_mj_nnls': e_point_nnls,\n","        'energy_upper95_mj_nnls': e_upper_nnls,\n","        'residual_mj': residuals[i]\n","    })\n","\n","results_df = pd.DataFrame(results)\n","results_df.to_csv('logs/fit_results.csv', index=False)\n","\n","coeffs = {\n","    'alpha_flops_coefficient': float(alpha),\n","    'beta_bytes_coefficient': float(beta),\n","    'gamma_intercept': float(gamma_unscaled),\n","    'delta_95_mj': float(delta_95_t),\n","    'delta_95_z_mj': float(delta_95_z),\n","    'upper_method': 't-distribution',\n","    'units': 'mJ/inf',\n","    'formula': 'E = alpha * FLOPs + beta * Bytes + gamma',\n","    'method': 'WLS (weighted least squares)',\n","    'weights': '1 / SE^2 (SE from CI95)'\n","}\n","\n","with open('logs/alpha_beta_gamma.json', 'w') as f:\n","    json.dump(coeffs, f, indent=2)\n","\n","coeffs_nnls = {\n","    'alpha_flops_coefficient': float(alpha_nnls),\n","    'beta_bytes_coefficient': float(beta_nnls),\n","    'gamma_intercept': float(gamma_nnls_unscaled),\n","    'delta_95_mj': float(delta_95_t),\n","    'delta_95_z_mj': float(delta_95_z),\n","    'upper_method': 't-distribution',\n","    'r_squared': float(r2_nnls_w),\n","    'units': 'mJ/inf',\n","    'formula': 'E = alpha * FLOPs + beta * Bytes + gamma',\n","    'method': 'WLS with non-negative constraint',\n","    'note': 'Enforces non-negativity in scaled parameterization; unscaled gamma may be negative'\n","}\n","\n","with open('logs/alpha_beta_gamma_nnls.json', 'w') as f:\n","    json.dump(coeffs_nnls, f, indent=2)\n","\n","diag = {\n","    'r_squared_weighted': float(r2_w),\n","    'r_squared_nnls_weighted': float(r2_nnls_w),\n","    'r_squared_unweighted': float(r2_unw),\n","    'mse_unweighted': float(mse_unw),\n","    'rmse_unweighted_mj': float(rmse_unw),\n","    'rmse_weighted_mj': float(rmse_w),\n","    'residual_sigma_unweighted_mj': float(sigma_resid_unw),\n","    'residual_sigma_weighted_unitless': float(sigma_resid_w),\n","    'model_uncertainty_mj': float(sigma_model),\n","    'pooled_measurement_SE_mj': float(pooled_meas_SE),\n","    'pooled_measurement_var_mj2': float(pooled_meas_var),\n","    'total_uncertainty_mj': float(total_uncertainty),\n","    'delta_95_t_mj': float(delta_95_t),\n","    'delta_95_z_mj': float(delta_95_z),\n","    'z_critical': 1.96,\n","    't_critical': float(t_crit_overall),\n","    'n_samples': n,\n","    'degrees_of_freedom': n - p,\n","    'formula_upper': 'E_upper = E_point + delta_95_t_mj',\n","    'note': 'Model uncertainty uses weighted RMSE (mJ) for WLS consistency; Primary upper bound uses t-distribution'\n","}\n","\n","with open('logs/fit_diag.json', 'w') as f:\n","    json.dump(diag, f, indent=2)\n","\n","plt.figure(figsize=(12, 4))\n","\n","plt.subplot(1, 3, 1)\n","plt.scatter(y_pred, y, alpha=0.6, label='WLS', s=50)\n","plt.scatter(y_pred_nnls, y, alpha=0.4, marker='^', label='NNLS', s=50)\n","plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n","plt.xlabel('Predicted Energy (mJ)')\n","plt.ylabel('Measured Energy (mJ)')\n","plt.title(f'Prediction vs Measured (R²_w={r2_w:.3f})')\n","plt.grid(True, alpha=0.3)\n","plt.legend()\n","\n","plt.subplot(1, 3, 2)\n","stats.probplot(residuals, dist=\"norm\", plot=plt)\n","plt.title('Residuals Q-Q Plot')\n","plt.grid(True, alpha=0.3)\n","\n","plt.subplot(1, 3, 3)\n","plt.hist(residuals, bins=10, alpha=0.7, edgecolor='black')\n","plt.xlabel('Residual (mJ)')\n","plt.ylabel('Frequency')\n","plt.title(f'Residuals (RMSE={rmse_unw:.3f} mJ)')\n","plt.grid(True, alpha=0.3)\n","\n","plt.tight_layout()\n","plt.savefig('logs/fit_diagnostics.png', dpi=150, bbox_inches='tight')\n","plt.close()\n","\n","print(\"=\" * 70)\n","print(\"ENERGY MODEL FITTING (WLS)\")\n","print(\"=\" * 70)\n","print(f\"\\nFormula: E = α·FLOPs + β·Bytes + γ\")\n","print(f\"\\nWLS Coefficients:\")\n","print(f\"  α (FLOPs):  {alpha:.6e} mJ/FLOP\")\n","print(f\"  β (Bytes):  {beta:.6e} mJ/Byte\")\n","print(f\"  γ (const):  {gamma_unscaled:.6f} mJ\")\n","print(f\"\\nNon-negative WLS Coefficients:\")\n","print(f\"  α (FLOPs):  {alpha_nnls:.6e} mJ/FLOP\")\n","print(f\"  β (Bytes):  {beta_nnls:.6e} mJ/Byte\")\n","print(f\"  γ (const):  {gamma_nnls_unscaled:.6f} mJ\")\n","print(f\"\\nModel Quality:\")\n","print(f\"  R²_w (weighted):      {r2_w:.4f}\")\n","print(f\"  R²_nnls_w (weighted): {r2_nnls_w:.4f}\")\n","print(f\"  R² (unweighted):      {r2_unw:.4f}\")\n","print(f\"  RMSE_w (weighted):    {rmse_w:.4f} mJ\")\n","print(f\"  RMSE (unweighted):    {rmse_unw:.4f} mJ\")\n","print(f\"\\nUncertainty Analysis:\")\n","print(f\"  Model σ (RMSE_w):     {sigma_model:.4f} mJ  [weighted, WLS-consistent]\")\n","print(f\"  Pooled Meas SE:       {pooled_meas_SE:.4f} mJ\")\n","print(f\"  Total σ:              {total_uncertainty:.4f} mJ\")\n","print(f\"  Δ_95% (t={t_crit_overall:.3f}):      {delta_95_t:.4f} mJ  [PRIMARY]\")\n","print(f\"  Δ_95% (z=1.96):       {delta_95_z:.4f} mJ  [reference]\")\n","print(f\"\\n  Note: RMSE_unw = {rmse_unw:.4f} mJ (unweighted, for comparison)\")\n","print(f\"        σ_resid_w = {sigma_resid_w:.4f} [unitless whitened, WLS diagnostic]\")\n","print(f\"\\nUpper Bound Formula:\")\n","print(f\"  E_upper = E_point + {delta_95_t:.4f} mJ  (t-distribution)\")\n","print(\"\\n\" + \"=\" * 70)\n","print(\"PREDICTIONS\")\n","print(\"=\" * 70)\n","print(f\"{'Model':<20} {'Measured':<10} {'Pred(WLS)':<10} {'Upper95':<10} {'Pred(NNLS)':<11} {'Residual':<10}\")\n","print(\"-\" * 70)\n","for _, row in results_df.iterrows():\n","    print(f\"{row['model']:<20} {row['energy_measured_mj']:>9.3f} {row['energy_predicted_mj']:>9.3f} \"\n","          f\"{row['energy_upper95_mj']:>9.3f} {row['energy_predicted_mj_nnls']:>10.3f} {row['residual_mj']:>9.3f}\")\n","print(\"\\n\" + \"=\" * 70)\n","print(\"✓ WLS coefficients saved to logs/alpha_beta_gamma.json\")\n","print(\"✓ NNLS coefficients saved to logs/alpha_beta_gamma_nnls.json\")\n","print(\"✓ Diagnostics saved to logs/fit_diag.json\")\n","print(\"✓ Fit results saved to logs/fit_results.csv\")\n","print(\"✓ Diagnostic plots saved to logs/fit_diagnostics.png\")\n","print(\"=\" * 70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iID4ghMb0j3s","executionInfo":{"status":"ok","timestamp":1762175108595,"user_tz":0,"elapsed":703,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"d8629825-5053-4c5e-c5cc-00e5744c674b"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","ENERGY MODEL FITTING (WLS)\n","======================================================================\n","\n","Formula: E = α·FLOPs + β·Bytes + γ\n","\n","WLS Coefficients:\n","  α (FLOPs):  5.666402e-08 mJ/FLOP\n","  β (Bytes):  2.035497e-07 mJ/Byte\n","  γ (const):  1.734014 mJ\n","\n","Non-negative WLS Coefficients:\n","  α (FLOPs):  5.666402e-08 mJ/FLOP\n","  β (Bytes):  2.035497e-07 mJ/Byte\n","  γ (const):  1.734014 mJ\n","\n","Model Quality:\n","  R²_w (weighted):      0.7165\n","  R²_nnls_w (weighted): 0.7165\n","  R² (unweighted):      0.5358\n","  RMSE_w (weighted):    0.9315 mJ\n","  RMSE (unweighted):    1.6510 mJ\n","\n","Uncertainty Analysis:\n","  Model σ (RMSE_w):     0.9315 mJ  [weighted, WLS-consistent]\n","  Pooled Meas SE:       0.6110 mJ\n","  Total σ:              1.1140 mJ\n","  Δ_95% (t=3.182):      3.5453 mJ  [PRIMARY]\n","  Δ_95% (z=1.96):       2.1835 mJ  [reference]\n","\n","  Note: RMSE_unw = 1.6510 mJ (unweighted, for comparison)\n","        σ_resid_w = 3.3833 [unitless whitened, WLS diagnostic]\n","\n","Upper Bound Formula:\n","  E_upper = E_point + 3.5453 mJ  (t-distribution)\n","\n","======================================================================\n","PREDICTIONS\n","======================================================================\n","Model                Measured   Pred(WLS)  Upper95    Pred(NNLS)  Residual  \n","----------------------------------------------------------------------\n","RandomForest             3.805     1.746     5.292      1.746     2.059\n","KNN                      8.389     8.400    11.945      8.400    -0.011\n","MiniROCKET               0.361     3.305     6.850      3.305    -2.944\n","MultiROCKET              3.178     4.875     8.420      4.875    -1.697\n","TST                      4.921     4.266     7.811      4.266     0.655\n","InceptionTime            2.907     3.281     6.827      3.281    -0.374\n","\n","======================================================================\n","✓ WLS coefficients saved to logs/alpha_beta_gamma.json\n","✓ NNLS coefficients saved to logs/alpha_beta_gamma_nnls.json\n","✓ Diagnostics saved to logs/fit_diag.json\n","✓ Fit results saved to logs/fit_results.csv\n","✓ Diagnostic plots saved to logs/fit_diagnostics.png\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["step 9"],"metadata":{"id":"NTJSjiII2KD9"}},{"cell_type":"code","source":["import os\n","import json\n","import numpy as np\n","import pandas as pd\n","\n","os.makedirs('results', exist_ok=True)\n","\n","macs_df = pd.read_csv('logs/macs_per_inf.csv')\n","bytes_df = pd.read_csv('logs/bytes_per_inf.csv')\n","calib_df = pd.read_csv('calibration/calibration_measurements.csv')\n","\n","for _df in (macs_df, bytes_df, calib_df):\n","    if 'window_ms' in _df.columns:\n","        _df['window_ms'] = pd.to_numeric(_df['window_ms'], errors='coerce').astype('Int64')\n","\n","with open('logs/alpha_beta_gamma.json', 'r') as f:\n","    coeffs = json.load(f)\n","\n","with open('configs/windows.json', 'r') as f:\n","    window_config = json.load(f)\n","\n","alpha = coeffs['alpha_flops_coefficient']\n","beta = coeffs['beta_bytes_coefficient']\n","gamma = coeffs['gamma_intercept']\n","delta_95 = max(0.0, float(coeffs.get('delta_95_mj', 0.0)))\n","\n","if 'window_grid_ms' in window_config:\n","    windows_ms = window_config['window_grid_ms']\n","elif 'windows_ms' in window_config:\n","    windows_ms = window_config['windows_ms']\n","else:\n","    windows_ms = [window_config['window']['window_ms']]\n","\n","windows_ms = [int(w) for w in windows_ms]\n","refresh_rates_hz = [float(hz) for hz in window_config['refresh_rates_hz'] if float(hz) >= 0.0]\n","latency_proxy_k = window_config.get('latency_proxy_ms_per_mj', 0.01)\n","\n","has_window_col_macs = 'window_ms' in macs_df.columns\n","has_window_col_bytes = 'window_ms' in bytes_df.columns\n","\n","base_window_ms = int(window_config.get('complexity_base_window_ms',\n","                     window_config.get('window', {}).get('window_ms', windows_ms[0])))\n","\n","if has_window_col_macs:\n","    macs_clean = macs_df.dropna(subset=['window_ms'])\n","    flops_dict = {(r['model'], int(r['window_ms'])): float(r['macs_per_inf']) * 2.0\n","                  for _, r in macs_clean.iterrows()}\n","    flops_source = 'measured'\n","else:\n","    flops_base = {row['model']: float(row['macs_per_inf']) * 2.0 for _, row in macs_df.iterrows()}\n","    flops_dict = {(m, int(w)): flops_base[m] * (float(w) / base_window_ms)\n","                  for m in flops_base for w in windows_ms}\n","    flops_source = f'scaled_linear_from_{base_window_ms}ms'\n","\n","bytes_col = 'total_bytes' if 'total_bytes' in bytes_df.columns else 'bytes_per_inf'\n","if has_window_col_bytes:\n","    bytes_clean = bytes_df.dropna(subset=['window_ms'])\n","    bytes_dict = {(r['model'], int(r['window_ms'])): float(r[bytes_col])\n","                  for _, r in bytes_clean.iterrows()}\n","    bytes_source = 'measured'\n","else:\n","    bytes_base = {row['model']: float(row[bytes_col]) for _, row in bytes_df.iterrows()}\n","    bytes_dict = {(m, int(w)): bytes_base[m] * (float(w) / base_window_ms)\n","                  for m in bytes_base for w in windows_ms}\n","    bytes_source = f'scaled_linear_from_{base_window_ms}ms'\n","\n","has_window_col_calib = 'window_ms' in calib_df.columns\n","if has_window_col_calib:\n","    calib_clean = calib_df.dropna(subset=['window_ms'])\n","    latency_measured = {(r['model'], int(r['window_ms'])): float(r['mean_latency_ms_per_inf'])\n","                        for _, r in calib_clean.iterrows()}\n","else:\n","    calib_base_window = int(window_config.get('latency_base_window_ms', windows_ms[0]))\n","    latency_measured = {(row['model'], calib_base_window): float(row['mean_latency_ms_per_inf'])\n","                        for _, row in calib_df.iterrows()}\n","\n","k_flops_per_ms = None\n","ratios = []\n","for (m, w), lat in latency_measured.items():\n","    if pd.isna(w):\n","        continue\n","    fl = flops_dict.get((m, int(w)))\n","    if (fl is not None) and np.isfinite(fl) and (lat is not None) and np.isfinite(lat) and (lat > 0):\n","        ratios.append(fl / lat)\n","if ratios:\n","    k_flops_per_ms = float(np.median(ratios))\n","\n","models = sorted(set(m for m, _ in flops_dict.keys()) & set(m for m, _ in bytes_dict.keys()))\n","\n","missing = [(m, w) for m in models for w in windows_ms\n","           if (m, w) not in flops_dict or (m, w) not in bytes_dict]\n","if missing:\n","    print(f\"NOTE: skipped {len(missing)} (model,window) pairs without FLOPs/Bytes. Example: {missing[:5]}\")\n","\n","results = []\n","\n","for model in models:\n","    measured_windows = {w for (m, w) in latency_measured.keys() if m == model}\n","\n","    for window_ms in windows_ms:\n","        key = (model, window_ms)\n","\n","        if key not in flops_dict or key not in bytes_dict:\n","            continue\n","\n","        flops = flops_dict[key]\n","        bytes_val = bytes_dict[key]\n","\n","        energy_point = max(0.0, alpha * flops + beta * bytes_val + gamma)\n","        energy_upper = max(energy_point, energy_point + max(0.0, float(delta_95)))\n","\n","        if key in latency_measured:\n","            latency_ms = latency_measured[key]\n","            latency_source = 'measured'\n","            latency_base_window_ms = window_ms\n","        elif measured_windows:\n","            latency_base_window_ms = min(measured_windows, key=lambda w: abs(int(w) - int(window_ms)))\n","            base_latency = latency_measured[(model, latency_base_window_ms)]\n","            latency_ms = base_latency * (float(window_ms) / float(latency_base_window_ms))\n","            latency_source = f'window_linear_from_{latency_base_window_ms}ms'\n","        else:\n","            if k_flops_per_ms is not None and k_flops_per_ms > 0:\n","                latency_ms = flops / k_flops_per_ms\n","                latency_source = 'flops_proxy'\n","            else:\n","                latency_ms = energy_point * latency_proxy_k\n","                latency_source = f'energy_proxy_k={latency_proxy_k}'\n","            latency_base_window_ms = np.nan\n","\n","        latency_ms = max(0.0, float(latency_ms))\n","        max_schedulable_hz = 1000.0 / max(latency_ms, 1e-9)\n","        edp = energy_point * latency_ms\n","\n","        for refresh_hz in refresh_rates_hz:\n","            power_point_mj_per_s = energy_point * refresh_hz\n","            power_upper_mj_per_s = energy_upper * refresh_hz\n","            power_point_mw = power_point_mj_per_s\n","            power_upper_mw = power_upper_mj_per_s\n","\n","            utilization = refresh_hz * latency_ms / 1000.0\n","            schedulable = utilization <= 1.0 + 1e-9\n","\n","            results.append({\n","                'model': model,\n","                'window_ms': window_ms,\n","                'refresh_rate_hz': refresh_hz,\n","                'flops_per_inf': flops,\n","                'bytes_per_inf': bytes_val,\n","                'flops_source': flops_source,\n","                'bytes_source': bytes_source,\n","                'energy_point_mj_per_inf': energy_point,\n","                'energy_upper95_mj_per_inf': energy_upper,\n","                'latency_ms_per_inf': latency_ms,\n","                'latency_source': latency_source,\n","                'latency_base_window_ms': latency_base_window_ms,\n","                'max_schedulable_hz': max_schedulable_hz,\n","                'edp_mj_ms': edp,\n","                'power_point_mj_per_s': power_point_mj_per_s,\n","                'power_upper95_mj_per_s': power_upper_mj_per_s,\n","                'power_point_mw': power_point_mw,\n","                'power_upper95_mw': power_upper_mw,\n","                'utilization': utilization,\n","                'schedulable': schedulable\n","            })\n","\n","df = pd.DataFrame(results)\n","df = df.sort_values(['model', 'window_ms', 'refresh_rate_hz'])\n","df.to_csv('results/proxy_energy_estimates.csv', index=False)\n","\n","print(\"=\" * 70)\n","print(\"PROXY ENERGY ESTIMATES\")\n","print(\"=\" * 70)\n","print(f\"\\nWindows: {windows_ms} ms\")\n","print(f\"Base window (for scaling): {base_window_ms} ms\")\n","print(f\"Models: {len(models)}\")\n","print(f\"Refresh rates: {refresh_rates_hz} Hz\")\n","print(f\"\\nCoefficients:\")\n","print(f\"  α = {alpha:.6e} mJ/FLOP\")\n","print(f\"  β = {beta:.6e} mJ/Byte\")\n","print(f\"  γ = {gamma:.6f} mJ\")\n","print(f\"  Δ₉₅ = {delta_95:.4f} mJ (non-negative protected)\")\n","print(f\"\\nComplexity sources:\")\n","print(f\"  FLOPs: {flops_source}\")\n","print(f\"  Bytes: {bytes_source}\")\n","print(f\"\\nLatency extrapolation:\")\n","print(f\"  Priority: measured > window_linear > flops_proxy > energy_proxy\")\n","if k_flops_per_ms:\n","    print(f\"  k_flops_per_ms = {k_flops_per_ms:.2e} FLOPs/ms (median, de-duplicated)\")\n","print(f\"  Energy proxy k = {latency_proxy_k} ms/mJ\")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"ESTIMATES SUMMARY (per model, first window)\")\n","print(\"=\" * 70)\n","first_window = windows_ms[0]\n","print(f\"{'Model':<20} {'E(mJ)':<10} {'Upper':<10} {'Lat(ms)':<10} {'Source':<35}\")\n","print(\"-\" * 70)\n","for model in models:\n","    model_data = df[(df['model'] == model) & (df['window_ms'] == first_window)]\n","    if len(model_data) > 0:\n","        row = model_data.iloc[0]\n","        print(f\"{model:<20} {row['energy_point_mj_per_inf']:>9.3f} \"\n","              f\"{row['energy_upper95_mj_per_inf']:>9.3f} \"\n","              f\"{row['latency_ms_per_inf']:>9.3f} {row['latency_source']:<35}\")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"SCHEDULABILITY CHECK (Utilization = refresh_hz × latency / 1000)\")\n","print(\"=\" * 70)\n","unschedulable = df[~df['schedulable']]\n","if len(unschedulable) > 0:\n","    print(f\"⚠ {len(unschedulable)} unschedulable configs (U > 1.0):\")\n","    for _, row in unschedulable.head(10).iterrows():\n","        print(f\"  {row['model']}, {row['window_ms']}ms, {row['refresh_rate_hz']}Hz: \"\n","              f\"U={row['utilization']:.2f}, max_hz={row['max_schedulable_hz']:.2f}\")\n","else:\n","    print(\"✓ All configurations schedulable (with 1e-9 tolerance)\")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"OUTPUT COLUMNS (results/proxy_energy_estimates.csv)\")\n","print(\"=\" * 70)\n","print(\"  model, window_ms, refresh_rate_hz\")\n","print(\"  flops_per_inf, bytes_per_inf\")\n","print(\"  flops_source, bytes_source (measured / scaled_linear_from_XXms)\")\n","print(\"  energy_point_mj_per_inf, energy_upper95_mj_per_inf\")\n","print(\"  latency_ms_per_inf, latency_source, latency_base_window_ms\")\n","print(\"  max_schedulable_hz (= 1000 / latency_ms)\")\n","print(\"  edp_mj_ms (E×D product)\")\n","print(\"  power_point_mj_per_s, power_upper95_mj_per_s\")\n","print(\"  power_point_mw, power_upper95_mw (mW = mJ/s)\")\n","print(\"  utilization, schedulable\")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"✓ Proxy estimates saved to results/proxy_energy_estimates.csv\")\n","print(f\"✓ Total rows: {len(df)} ({len(models)} models × {len(windows_ms)} windows × {len(refresh_rates_hz)} rates)\")\n","print(\"=\" * 70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5XjbkBU5-GyP","executionInfo":{"status":"ok","timestamp":1762177610325,"user_tz":0,"elapsed":37,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"b50d81ef-d195-478b-880e-656d59ef8149"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","PROXY ENERGY ESTIMATES\n","======================================================================\n","\n","Windows: [2560] ms\n","Base window (for scaling): 2560 ms\n","Models: 6\n","Refresh rates: [0.1, 0.5, 1.0, 2.0] Hz\n","\n","Coefficients:\n","  α = 5.666402e-08 mJ/FLOP\n","  β = 2.035497e-07 mJ/Byte\n","  γ = 1.734014 mJ\n","  Δ₉₅ = 3.5453 mJ (non-negative protected)\n","\n","Complexity sources:\n","  FLOPs: scaled_linear_from_2560ms\n","  Bytes: scaled_linear_from_2560ms\n","\n","Latency extrapolation:\n","  Priority: measured > window_linear > flops_proxy > energy_proxy\n","  k_flops_per_ms = 1.91e+07 FLOPs/ms (median, de-duplicated)\n","  Energy proxy k = 0.01 ms/mJ\n","\n","======================================================================\n","ESTIMATES SUMMARY (per model, first window)\n","======================================================================\n","Model                E(mJ)      Upper      Lat(ms)    Source                             \n","----------------------------------------------------------------------\n","InceptionTime            3.281     6.827     1.204 measured                           \n","KNN                      8.400    11.945     3.046 measured                           \n","MiniROCKET               3.305     6.850     0.487 measured                           \n","MultiROCKET              4.875     8.420     1.268 measured                           \n","RandomForest             1.746     5.292    18.523 measured                           \n","TST                      4.266     7.811     1.700 measured                           \n","\n","======================================================================\n","SCHEDULABILITY CHECK (Utilization = refresh_hz × latency / 1000)\n","======================================================================\n","✓ All configurations schedulable (with 1e-9 tolerance)\n","\n","======================================================================\n","OUTPUT COLUMNS (results/proxy_energy_estimates.csv)\n","======================================================================\n","  model, window_ms, refresh_rate_hz\n","  flops_per_inf, bytes_per_inf\n","  flops_source, bytes_source (measured / scaled_linear_from_XXms)\n","  energy_point_mj_per_inf, energy_upper95_mj_per_inf\n","  latency_ms_per_inf, latency_source, latency_base_window_ms\n","  max_schedulable_hz (= 1000 / latency_ms)\n","  edp_mj_ms (E×D product)\n","  power_point_mj_per_s, power_upper95_mj_per_s\n","  power_point_mw, power_upper95_mw (mW = mJ/s)\n","  utilization, schedulable\n","\n","======================================================================\n","✓ Proxy estimates saved to results/proxy_energy_estimates.csv\n","✓ Total rows: 24 (6 models × 1 windows × 4 rates)\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["step 10"],"metadata":{"id":"WjX5YlPCFZOK"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib\n","matplotlib.use('Agg')\n","\n","os.makedirs('figures', exist_ok=True)\n","\n","df = pd.read_csv('results/proxy_energy_estimates.csv')\n","metrics_df = pd.read_csv('logs/train_metrics.csv')\n","\n","accuracy_dict = dict(zip(metrics_df['model'], metrics_df['test_accuracy']))\n","\n","df['accuracy'] = df['model'].map(accuracy_dict)\n","\n","fig_note = \"Proxy estimates from GPU-NVML calibration; not edge-device measurements\"\n","\n","models = df['model'].unique()\n","colors = plt.cm.tab10(np.linspace(0, 1, len(models)))\n","model_colors = dict(zip(models, colors))\n","\n","first_window = df['window_ms'].min()\n","first_rate = df['refresh_rate_hz'].min()\n","\n","fig, ax = plt.subplots(figsize=(10, 6))\n","for model in models:\n","    model_df = df[(df['model'] == model) & (df['window_ms'] == first_window) & (df['refresh_rate_hz'] == first_rate)]\n","    if len(model_df) == 0:\n","        continue\n","    row = model_df.iloc[0]\n","    ax.scatter(row['energy_point_mj_per_inf'], row['accuracy'],\n","               color=model_colors[model], s=100, label=f\"{model} (point)\", marker='o')\n","    ax.scatter(row['energy_upper95_mj_per_inf'], row['accuracy'],\n","               color=model_colors[model], s=100, alpha=0.5, marker='x')\n","    ax.plot([row['energy_point_mj_per_inf'], row['energy_upper95_mj_per_inf']],\n","            [row['accuracy'], row['accuracy']],\n","            color=model_colors[model], alpha=0.3, linewidth=2)\n","\n","ax.set_xlabel('Energy per Inference (mJ)', fontsize=12)\n","ax.set_ylabel('Test Accuracy', fontsize=12)\n","ax.set_title(f'Accuracy vs Energy (window={first_window}ms, rate={first_rate}Hz)', fontsize=13)\n","ax.legend(fontsize=9, loc='best')\n","ax.grid(True, alpha=0.3)\n","ax.text(0.02, 0.02, fig_note, transform=ax.transAxes, fontsize=8,\n","        verticalalignment='bottom', style='italic', color='gray')\n","plt.tight_layout()\n","plt.savefig('figures/accuracy_vs_energy.png', dpi=150, bbox_inches='tight')\n","plt.close()\n","\n","fig, ax = plt.subplots(figsize=(10, 6))\n","for model in models:\n","    model_df = df[(df['model'] == model) & (df['window_ms'] == first_window) & (df['refresh_rate_hz'] == first_rate)]\n","    if len(model_df) == 0:\n","        continue\n","    row = model_df.iloc[0]\n","    ax.scatter(row['latency_ms_per_inf'], row['energy_point_mj_per_inf'],\n","               color=model_colors[model], s=100, label=model, marker='o')\n","    ax.errorbar(row['latency_ms_per_inf'], row['energy_point_mj_per_inf'],\n","                yerr=[[0], [row['energy_upper95_mj_per_inf'] - row['energy_point_mj_per_inf']]],\n","                fmt='none', color=model_colors[model], alpha=0.5, capsize=5)\n","\n","ax.set_xlabel('Latency per Inference (ms)', fontsize=12)\n","ax.set_ylabel('Energy per Inference (mJ)', fontsize=12)\n","ax.set_title(f'Energy vs Latency (window={first_window}ms, rate={first_rate}Hz)', fontsize=13)\n","ax.legend(fontsize=9, loc='best')\n","ax.grid(True, alpha=0.3)\n","ax.text(0.02, 0.98, fig_note, transform=ax.transAxes, fontsize=8,\n","        verticalalignment='top', style='italic', color='gray')\n","plt.tight_layout()\n","plt.savefig('figures/energy_vs_latency.png', dpi=150, bbox_inches='tight')\n","plt.close()\n","\n","windows = sorted(df['window_ms'].unique())\n","fig, ax = plt.subplots(figsize=(10, 6))\n","for model in models:\n","    edps = []\n","    for w in windows:\n","        model_df = df[(df['model'] == model) & (df['window_ms'] == w) & (df['refresh_rate_hz'] == first_rate)]\n","        if len(model_df) > 0:\n","            edps.append(model_df.iloc[0]['edp_mj_ms'])\n","        else:\n","            edps.append(np.nan)\n","    ax.plot(windows, edps, marker='o', label=model, color=model_colors[model], linewidth=2)\n","\n","ax.set_xlabel('Window Duration (ms)', fontsize=12)\n","ax.set_ylabel('Energy-Delay Product (mJ·ms)', fontsize=12)\n","ax.set_title(f'EDP vs Window (rate={first_rate}Hz)', fontsize=13)\n","ax.legend(fontsize=9, loc='best')\n","ax.grid(True, alpha=0.3)\n","ax.text(0.02, 0.98, fig_note, transform=ax.transAxes, fontsize=8,\n","        verticalalignment='top', style='italic', color='gray')\n","plt.tight_layout()\n","plt.savefig('figures/edp_vs_window.png', dpi=150, bbox_inches='tight')\n","plt.close()\n","\n","rates = sorted(df['refresh_rate_hz'].unique())\n","fig, ax = plt.subplots(figsize=(10, 6))\n","for model in models:\n","    powers = []\n","    power_uppers = []\n","    for r in rates:\n","        model_df = df[(df['model'] == model) & (df['window_ms'] == first_window) & (df['refresh_rate_hz'] == r)]\n","        if len(model_df) > 0:\n","            powers.append(model_df.iloc[0]['power_point_mj_per_s'])\n","            power_uppers.append(model_df.iloc[0]['power_upper95_mj_per_s'])\n","        else:\n","            powers.append(np.nan)\n","            power_uppers.append(np.nan)\n","\n","    ax.plot(rates, powers, marker='o', label=f\"{model} (point)\", color=model_colors[model], linewidth=2)\n","    ax.fill_between(rates, powers, power_uppers, color=model_colors[model], alpha=0.2)\n","\n","ax.set_xlabel('Refresh Rate (Hz)', fontsize=12)\n","ax.set_ylabel('Power (mJ/s = mW)', fontsize=12)\n","ax.set_title(f'Power vs Refresh Rate (window={first_window}ms)', fontsize=13)\n","ax.legend(fontsize=9, loc='best')\n","ax.grid(True, alpha=0.3)\n","ax.text(0.02, 0.98, fig_note, transform=ax.transAxes, fontsize=8,\n","        verticalalignment='top', style='italic', color='gray')\n","plt.tight_layout()\n","plt.savefig('figures/power_vs_refresh_rate.png', dpi=150, bbox_inches='tight')\n","plt.close()\n","\n","print(\"=\" * 70)\n","print(\"VISUALIZATION COMPLETE\")\n","print(\"=\" * 70)\n","print(f\"\\nGenerated figures:\")\n","print(f\"  1. figures/accuracy_vs_energy.png\")\n","print(f\"  2. figures/energy_vs_latency.png\")\n","print(f\"  3. figures/edp_vs_window.png\")\n","print(f\"  4. figures/power_vs_refresh_rate.png\")\n","print(f\"\\nData points:\")\n","print(f\"  Models: {len(models)}\")\n","print(f\"  Windows: {windows}\")\n","print(f\"  Refresh rates: {rates}\")\n","print(\"\\n\" + \"=\" * 70)\n","print(\"✓ All visualizations saved to figures/\")\n","print(\"=\" * 70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qgwuHcAi_I0t","executionInfo":{"status":"ok","timestamp":1762178392268,"user_tz":0,"elapsed":1641,"user":{"displayName":"yu Wu","userId":"12692660435918028293"}},"outputId":"3a18ce8d-d855-4faa-ce1e-39b2a258d548"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","VISUALIZATION COMPLETE\n","======================================================================\n","\n","Generated figures:\n","  1. figures/accuracy_vs_energy.png\n","  2. figures/energy_vs_latency.png\n","  3. figures/edp_vs_window.png\n","  4. figures/power_vs_refresh_rate.png\n","\n","Data points:\n","  Models: 6\n","  Windows: [np.int64(2560)]\n","  Refresh rates: [np.float64(0.1), np.float64(0.5), np.float64(1.0), np.float64(2.0)]\n","\n","======================================================================\n","✓ All visualizations saved to figures/\n","======================================================================\n"]}]}]}